{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Содержание проекта:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Исследование-данных-Бета-Банка\" data-toc-modified-id=\"Исследование-данных-Бета-Банка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Исследование данных Бета-Банка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Открываем-файл-с-данными-и-анализируем-содержимое\" data-toc-modified-id=\"Открываем-файл-с-данными-и-анализируем-содержимое-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Открываем файл с данными и анализируем содержимое</a></span></li></ul></li><li><span><a href=\"#Предобработка-данных-таблицы\" data-toc-modified-id=\"Предобработка-данных-таблицы-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Предобработка данных таблицы</a></span><ul class=\"toc-item\"><li><span><a href=\"#Удаляем-столбец\" data-toc-modified-id=\"Удаляем-столбец-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Удаляем столбец</a></span></li><li><span><a href=\"#Переименовываем-столбцы\" data-toc-modified-id=\"Переименовываем-столбцы-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Переименовываем столбцы</a></span></li><li><span><a href=\"#Явные-дубликаты\" data-toc-modified-id=\"Явные-дубликаты-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Явные дубликаты</a></span></li><li><span><a href=\"#Не-явные-дубликаты\" data-toc-modified-id=\"Не-явные-дубликаты-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Не явные дубликаты</a></span></li><li><span><a href=\"#Исследуем-столбец-tenure\" data-toc-modified-id=\"Исследуем-столбец-tenure-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Исследуем столбец tenure</a></span></li></ul></li><li><span><a href=\"#Удаление-столбцов-из-таблицы,-не-влияющих-на-обучение-моделей-предсказаний\" data-toc-modified-id=\"Удаление-столбцов-из-таблицы,-не-влияющих-на-обучение-моделей-предсказаний-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Удаление столбцов из таблицы, не влияющих на обучение моделей предсказаний</a></span></li><li><span><a href=\"#Преобразование-категориальных-данных-в-числовые,-метод-OHE\" data-toc-modified-id=\"Преобразование-категориальных-данных-в-числовые,-метод-OHE-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Преобразование категориальных данных в числовые, метод OHE</a></span></li><li><span><a href=\"#Массштабирование-признаков\" data-toc-modified-id=\"Массштабирование-признаков-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Массштабирование признаков</a></span></li><li><span><a href=\"#Разделим-исходные-данные-на-обучающую,-валидационную-и-тестовую-выборки-без-стратификации-и-баланса-классов.\" data-toc-modified-id=\"Разделим-исходные-данные-на-обучающую,-валидационную-и-тестовую-выборки-без-стратификации-и-баланса-классов.-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Разделим исходные данные на обучающую, валидационную и тестовую выборки без стратификации и баланса классов.</a></span></li><li><span><a href=\"#Исследуем-качество-F1-меры-разных-моделей-на-данных-без-стратификации,-меняя-гиперпараметры.\" data-toc-modified-id=\"Исследуем-качество-F1-меры-разных-моделей-на-данных-без-стратификации,-меняя-гиперпараметры.-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Исследуем качество F1-меры разных моделей на данных без стратификации, меняя гиперпараметры.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Модель-решающего-дерева:\" data-toc-modified-id=\"Модель-решающего-дерева:-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Модель решающего дерева:</a></span></li><li><span><a href=\"#Модель-случайного-леса\" data-toc-modified-id=\"Модель-случайного-леса-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Модель случайного леса</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li></ul></li><li><span><a href=\"#Разделим-исходные-данные-на-обучающую,-валидационную-и-тестовую-выборки-учитывая-стратификацию-классов.\" data-toc-modified-id=\"Разделим-исходные-данные-на-обучающую,-валидационную-и-тестовую-выборки-учитывая-стратификацию-классов.-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Разделим исходные данные на обучающую, валидационную и тестовую выборки учитывая стратификацию классов.</a></span></li><li><span><a href=\"#Исследуем-качество-F1-меры-разных-моделей-на-данных-c-учетом-баланса-классов,-меняя-гиперпараметры.\" data-toc-modified-id=\"Исследуем-качество-F1-меры-разных-моделей-на-данных-c-учетом-баланса-классов,-меняя-гиперпараметры.-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Исследуем качество F1-меры разных моделей на данных c учетом баланса классов, меняя гиперпараметры.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Модель-решающего-дерева:\" data-toc-modified-id=\"Модель-решающего-дерева:-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Модель решающего дерева:</a></span></li><li><span><a href=\"#Модель-случайного-леса\" data-toc-modified-id=\"Модель-случайного-леса-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Модель случайного леса</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-9.3\"><span class=\"toc-item-num\">9.3&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li></ul></li><li><span><a href=\"#Проверим-качество-модели-на-тестовой-выборке-с-учетом-баланса-классов.\" data-toc-modified-id=\"Проверим-качество-модели-на-тестовой-выборке-с-учетом-баланса-классов.-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Проверим качество модели на тестовой выборке с учетом баланса классов.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Модель-решающего-дерева---обучение-на-60%-данных\" data-toc-modified-id=\"Модель-решающего-дерева---обучение-на-60%-данных-10.1\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span>Модель решающего дерева - обучение на 60% данных</a></span></li><li><span><a href=\"#Модель-случайного-леса---обучение-на-60%-данных\" data-toc-modified-id=\"Модель-случайного-леса---обучение-на-60%-данных-10.2\"><span class=\"toc-item-num\">10.2&nbsp;&nbsp;</span>Модель случайного леса - обучение на 60% данных</a></span></li><li><span><a href=\"#Разделим-данные-на-тренировочные-и-тестовые-80\\20\" data-toc-modified-id=\"Разделим-данные-на-тренировочные-и-тестовые-80\\20-10.3\"><span class=\"toc-item-num\">10.3&nbsp;&nbsp;</span>Разделим данные на тренировочные и тестовые 80\\20</a></span></li><li><span><a href=\"#Модель-решающего-дерева---обучение-на-80%-данных\" data-toc-modified-id=\"Модель-решающего-дерева---обучение-на-80%-данных-10.4\"><span class=\"toc-item-num\">10.4&nbsp;&nbsp;</span>Модель решающего дерева - обучение на 80% данных</a></span></li><li><span><a href=\"#Модель-случайного-леса---обучение-на-80%-данных\" data-toc-modified-id=\"Модель-случайного-леса---обучение-на-80%-данных-10.5\"><span class=\"toc-item-num\">10.5&nbsp;&nbsp;</span>Модель случайного леса - обучение на 80% данных</a></span></li><li><span><a href=\"#Модель-случайного-леса-на-данных-без-массштабирования\" data-toc-modified-id=\"Модель-случайного-леса-на-данных-без-массштабирования-10.6\"><span class=\"toc-item-num\">10.6&nbsp;&nbsp;</span>Модель случайного леса на данных без массштабирования</a></span></li><li><span><a href=\"#ROC-кривая-лучшей-модели\" data-toc-modified-id=\"ROC-кривая-лучшей-модели-10.7\"><span class=\"toc-item-num\">10.7&nbsp;&nbsp;</span>ROC кривая лучшей модели</a></span></li><li><span><a href=\"#Модель-случайного-леса-на-данных-без-массштабирования-с-Дамми-ловушкой\" data-toc-modified-id=\"Модель-случайного-леса-на-данных-без-массштабирования-с-Дамми-ловушкой-10.8\"><span class=\"toc-item-num\">10.8&nbsp;&nbsp;</span>Модель случайного леса на данных без массштабирования с Дамми-ловушкой</a></span></li><li><span><a href=\"#Проверка-на-адекватность-моделей\" data-toc-modified-id=\"Проверка-на-адекватность-моделей-10.9\"><span class=\"toc-item-num\">10.9&nbsp;&nbsp;</span>Проверка на адекватность моделей</a></span></li><li><span><a href=\"#А-что-если-мы-уменьшим-количество-данных-с-нулями?\" data-toc-modified-id=\"А-что-если-мы-уменьшим-количество-данных-с-нулями?-10.10\"><span class=\"toc-item-num\">10.10&nbsp;&nbsp;</span>А что если мы уменьшим количество данных с нулями?</a></span></li></ul></li><li><span><a href=\"#Обобщим-исследования\" data-toc-modified-id=\"Обобщим-исследования-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Обобщим исследования</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The version of the notebook server is: 6.1.4\n",
    "\n",
    "The server is running on this version of Python: Python 3.8.5\n",
    "\n",
    "OS Windows 10 Home\n",
    "\n",
    "Configurable nbextensions Table of Contents (2) compatibility: 4.x, 5.x (https://www.codegrepper.com/code-examples/shell/install+toc2+jupyter+notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Описание проекта:</b>\n",
    "\n",
    "\n",
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.\n",
    "\n",
    "\n",
    "Постройте модель с предельно большим значением F1-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте F1-меру на тестовой выборке самостоятельно.\n",
    "\n",
    "\n",
    "Дополнительно измеряйте AUC-ROC, сравнивайте её значение с F1-мерой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # импорт библиотеки pandas\n",
    "import matplotlib.pyplot as plt # импорт библиотеки работы с графиками\n",
    "import numpy as np # импорт библиотеки для вычислений\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # отключаем сообщения об ошибках pandas\n",
    "pd.set_option('display.max_columns', None) # Сброс ограничений на число выводимых столбцов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование данных Бета-Банка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Открываем файл с данными и анализируем содержимое\n",
    "\n",
    "от Бета-Банка получен следующий файл: Churn.csv  отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для чтения файла в таблицу с учетом возможности работы на разных платформах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(link):\n",
    "    link1 = 'datasets/'+link\n",
    "    link2 = '/datasets/'+link\n",
    "    try:\n",
    "        name_link = pd.read_csv(link1)\n",
    "    except:\n",
    "        name_link = pd.read_csv(link2)\n",
    "    return name_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv('Churn.csv') #применяем функцию чтения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # просмотрим перве 10 строчек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() # просмотрим информацию о таблице"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблица содержит 10000 строк, требуется приеобразование всех имен столбцов в формат snake_case\n",
    "\n",
    "<b>Признаки:</b>\n",
    "\n",
    "* RowNumber — индекс строки в данных\n",
    "\n",
    "        тип данных int64 верный, пропусков нет, но этот столбец можно удалить из данных\n",
    "\n",
    "* CustomerId — уникальный идентификатор клиента\n",
    "\n",
    "        тип данных int64 верный, пропусков нет\n",
    "\n",
    "* Surname — фамилия\n",
    "\n",
    "        тип данных object верный, пропусков нет\n",
    "\n",
    "* CreditScore — кредитный рейтинг\n",
    "\n",
    "        тип данных int64 верный, пропусков нет\n",
    "\n",
    "* Geography — страна проживания\n",
    "\n",
    "        тип данных object верный, пропусков нет\n",
    "\n",
    "* Gender — пол\n",
    "\n",
    "        тип данных object верный, пропусков нет\n",
    "\n",
    "* Age — возраст\n",
    "\n",
    "        тип данных int64 верный, пропусков нет\n",
    "\n",
    "* Tenure — сколько лет человек является клиентом банка\n",
    "\n",
    "        тип данных float64, тут нужно проверить есть ли действительно десятые доли года в ячейках, если нет, то можно преобразовывать в int64, так же есть 909 пустых ячеек, проверить почему они пустые, и возможно ли их заполнить. Есть предположение, что пустые ячейки у новых клиентов.\n",
    "\n",
    "* Balance — баланс на счёте\n",
    "\n",
    "        тип данных float64 верный, пропусков нет\n",
    "\n",
    "* NumOfProducts — количество продуктов банка, используемых клиентом\n",
    "\n",
    "        тип данных int64 верный, пропусков нет\n",
    "\n",
    "* HasCrCard — наличие кредитной карты\n",
    "\n",
    "        тип данных int64 верный, пропусков нет\n",
    "\n",
    "* IsActiveMember — активность клиента\n",
    "\n",
    "        тип данных int64 верный, пропусков нет\n",
    "\n",
    "* EstimatedSalary — предполагаемая зарплата\n",
    "\n",
    "        тип данных float64 верный, пропусков нет\n",
    "\n",
    "\n",
    "<b>Целевой признак:</b>\n",
    "\n",
    "* Exited — факт ухода клиента\n",
    "\n",
    "        тип данных int64 верный, пропусков нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CreditScore           Age       Tenure        Balance  NumOfProducts  \\\n",
       "count  10000.000000  10000.000000  9091.000000   10000.000000   10000.000000   \n",
       "mean     650.528800     38.921800     4.997690   76485.889288       1.530200   \n",
       "std       96.653299     10.487806     2.894723   62397.405202       0.581654   \n",
       "min      350.000000     18.000000     0.000000       0.000000       1.000000   \n",
       "25%      584.000000     32.000000     2.000000       0.000000       1.000000   \n",
       "50%      652.000000     37.000000     5.000000   97198.540000       1.000000   \n",
       "75%      718.000000     44.000000     7.000000  127644.240000       2.000000   \n",
       "max      850.000000     92.000000    10.000000  250898.090000       4.000000   \n",
       "\n",
       "         HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "count  10000.00000    10000.000000     10000.000000  \n",
       "mean       0.70550        0.515100    100090.239881  \n",
       "std        0.45584        0.499797     57510.492818  \n",
       "min        0.00000        0.000000        11.580000  \n",
       "25%        0.00000        0.000000     51002.110000  \n",
       "50%        1.00000        1.000000    100193.915000  \n",
       "75%        1.00000        1.000000    149388.247500  \n",
       "max        1.00000        1.000000    199992.480000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']].describe()\n",
    "# просмотрим информацию о числовых данных в интересных столбцах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Вывод: \n",
    "\n",
    "Требуется предобработка данных, а именно:\n",
    "    \n",
    "    - удалить столбец RowNumber\n",
    "    - переименование столбцов в формат snake_case;\n",
    "    - исследование на явные дубликаты;\n",
    "    - исследовать столбцы с категориальными данным на не явные дубликаты;\n",
    "    - исследовать столбец Tenure - пустые значения в нем;\n",
    "\n",
    "    \n",
    "В остальном даннные вполне правдоподобные, нереальных выбросов не наблюдается.\n",
    "    \n",
    "\n",
    "Целевым параметром для модели предсказания является столбец Exited. так как в столбце лишь 1 и 0 то у нас формируется задача Классификации.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных таблицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаляем столбец"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['RowNumber'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переименовываем столбцы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как нужно переименовывать все столбцы то:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_axis(['customer_id', 'surname', 'credit_score', 'geography', 'gender', 'age',\n",
    "       'tenure', 'balance', 'num_products', 'has_card', 'active_member',\n",
    "       'estimated_salary', 'exited'],axis = 'columns',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'surname', 'credit_score', 'geography', 'gender', 'age',\n",
       "       'tenure', 'balance', 'num_products', 'has_card', 'active_member',\n",
       "       'estimated_salary', 'exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # проверим имена столбцов после переименования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Явные дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Не явные дубликаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим содержимое столбцов с категориальными данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальные значения в ячейках для столбца surname\n",
      "['Hargrave', 'Hill', 'Onio', 'Boni', 'Mitchell', 'Chu', 'Bartlett', 'Obinna', 'He', 'H?', 'Bearce', 'Andrews', 'Kay', 'Chin', 'Scott', 'Goforth', 'Romeo', 'Henderson', 'Muldrow', 'Hao', 'McDonald', 'Dellucci', 'Gerasimov', 'Mosman', 'Yen', 'Maclean', 'Young', 'Nebechi', 'McWilliams', 'Lucciano', 'Azikiwe', 'Odinakachukwu', 'Sanderson', 'Maggard', 'Clements', 'Lombardo', 'Watson', 'Lorenzo', 'Armstrong', 'Cameron', 'Hsiao', 'Clarke', 'Osborne', 'Lavine', 'Bianchi', 'Tyler', 'Martin', 'Okagbue', 'Yin', 'Buccho', 'Chidiebele', 'Trevisani', \"O'Brien\", 'Parkhill', 'Yoo', 'Phillipps', 'Tsao', 'Endrizzi', \"T'ien\", 'Velazquez', 'Hunter', 'Clark', 'Jeffrey', 'Pirozzi', 'Jackson', 'Hammond', 'Brownless', 'Chibugo', 'Glauert', 'Pisano', 'Konovalova', 'McKee', 'Palermo', 'Ballard', 'Wallace', 'Cavenagh', 'Hu', 'Read', 'Bushell', 'Postle', 'Buley', 'Leonard', 'Mills', 'Onyeorulu', 'Beit', 'Ndukaku', 'Gant', 'Rowley', 'Sharpe', 'Heap', 'Ritchie', 'Cole', 'Capon', 'Fiorentini', 'Graham', 'Yuille', 'Allard', 'Fanucci', 'Fu', 'Hung', 'Bradley', 'Dunbabin', 'Mauldon', 'Stiger', 'Parsons', 'Walkom', \"T'ang\", 'Eremenko', 'Rowntree', 'Thorpe', 'Chiemela', 'Ko', 'Welch', 'Duncan', 'Chidozie', 'Wu', 'Culbreth', 'Kennedy', 'Calabresi', 'Zetticci', 'Fuller', 'MacDonald', 'Piccio', 'Fernie', 'Kaodilinakachukwu', 'Cocci', 'Alekseeva', 'Chinweike', 'Arthur', 'Li', 'Ma', 'Chia', 'Vasin', 'Groves', 'Tien', 'Forwood', 'Greeves', 'Taylor', 'Madukwe', 'Bennelong', 'Olisanugo', 'Chukwufumnanya', 'Harris', 'Morgan', 'Alexeeva', 'Metcalfe', 'Humphries', 'Milne', 'Chou', 'Clayton', 'Chigolum', 'Wilkinson', 'Wei', 'Treacy', 'Taverner', 'Sherman', 'Taubman', 'Robinson', 'Pinto', 'Wood', 'Hawkins', 'Sun', 'Yost', 'Ting', 'Rowe', 'Ho', 'Okechukwu', 'Campbell', 'Ashbolt', 'Rozier', 'Hsia', 'Ogbonnaya', 'Chang', \"T'ao\", 'Ford', 'Marshall', 'Tsai', 'Onwumelu', 'Golovanov', 'Potts', 'Crawford', 'Aleshire', 'Moran', 'Samsonova', 'Jenkins', 'Volkov', 'Chiemezie', 'Jude', 'Onuora', 'Ginikanwa', 'Ku', 'Collins', 'Hackett', 'Dike', 'Trevisano', 'Tan', 'Glassman', 'Miller', 'Kornilova', 'Marchesi', 'Millar', 'Shih', 'Hay', 'Yang', 'McIntyre', 'Stevenson', 'Poole', 'Bagley', \"Ch'ien\", 'Cattaneo', \"O'Sullivan\", 'Lucas', 'Ringrose', 'Freeman', 'Sergeyev', 'Fiore', 'Smith', 'Dumetochukwu', 'Pacheco', 'Synnot', 'Johnston', 'Stevens', 'Grant', 'Barnes', 'McIntosh', 'Madison', 'Ifesinachi', 'Glazkov', 'Dimauro', 'Wieck', 'Liao', 'Hughes', 'Morrison', 'Matveyeva', 'Cheatham', 'Yao', 'Kirkland', 'Rose', 'Jess', 'Ifeajuna', 'Morton', 'Rossi', 'Reppert', 'Kang', \"Ch'iu\", 'Wallis', 'Fielding', 'Dulhunty', 'Bevington', 'Boyle', 'Newton', 'Bowman', 'Dubinina', 'Toscani', 'Chiazagomekpere', 'Allen', \"K'ung\", 'Wilsmore', 'Hargreaves', 'Huang', 'Wallwork', 'Davidson', \"O'Donnell\", 'Nnachetam', 'Ahmed', 'Booth', 'Chuang', 'Shao', 'Johnson', 'French', 'Efremov', 'Hartley', 'Calabrese', 'Chiu', 'Brennan', 'Onwuatuegwu', 'Hewitt', 'Balashov', 'Doyle', 'Pokrovskii', 'Russo', 'Skinner', 'Robertson', 'Atkinson', 'McEncroe', 'Pearson', 'Gordon', \"Ts'ai\", 'Lung', 'Yuan', 'Pardey', 'Tai', 'Mazzanti', 'L?', 'Beach', 'Hsieh', 'Faulkner', 'Knowles', 'Day', 'Hsueh', 'Nwabugwu', 'Kerr', 'Marrero', 'White', 'Brown', 'Russell', 'Seleznyov', 'Yusupova', 'Foley', 'Ikedinachukwu', 'Power', 'Amos', 'Reed', 'Simmons', 'Ricci', 'West', 'Chen', 'Madukaego', 'Ibrahimova', 'Nolan', 'Blair', 'Monaldo', 'Sutherland', 'Briggs', 'Gregory', 'Angelo', 'Gardiner', 'Distefano', 'Farrell', 'Milano', 'Boyd', 'Onyemaechi', 'Black', 'Oliver', 'Greco', 'Whitehead', 'Ikemefuna', 'Onyeoruru', 'Cunningham', 'Demidov', 'Celis', 'Cheng', 'Knight', 'Morin', 'Outhwaite', 'Tung', 'Pai', 'Carpenter', 'Fennell', 'Fontaine', 'Pratt', 'Franklin', 'McKenzie', 'Pino', 'Fisk', 'Chiang', 'Moseley', 'Hsiung', 'Heath', 'De Salis', 'Richardson', 'Fitch', 'Estes', 'Lattimore', 'Chung', 'Utz', 'Nwachinemelu', 'Kuznetsova', 'Pisani', 'Manna', 'Collier', 'Carr', 'Hs?', 'Findlay', 'Chukwuemeka', 'Genovese', 'Swift', 'Ugoji', 'Parkinson', 'Ross', 'Oleary', 'Turnbull', 'Uspensky', 'Cook', 'Newbold', 'Uchechukwu', \"Ch'en\", 'Hilton', 'Sal', 'Eluemuno', 'Titus', 'Lettiere', 'Templeman', 'Chibuzo', 'Evans', 'Enyinnaya', 'Brookes', 'Padovano', 'Hare', 'Muir', 'Elewechi', 'Ankudinov', 'Nwokike', 'Atkins', 'Burns', 'Obiuto', 'George', 'Lewis', 'Dalrymple', 'Carslaw', 'Kirby', 'Houghton', 'Westerberg', 'Hale', 'Kryukova', 'Sopuluchukwu', 'Barry', 'Selezneva', 'Chizuoke', 'Lueck', 'Udinese', 'Udobata', 'Outlaw', 'Lo', 'King', 'Forbes', 'Macleod', 'Gibbs', 'Isayev', 'Belstead', 'Vassiliev', 'Schneider', 'Knipe', 'Macartney', 'Watts', 'Humphreys', 'Chesnokova', 'Kung', 'Lu', 'Nkemakolam', 'Walton', 'Baldwin', 'Mai', 'Ferreira', 'Ukaegbunam', 'De Luca', 'Davide', 'Kodilinyechukwu', 'Little', 'Paterson', 'Han', 'Ijendu', 'Reichard', 'Price', 'Bruce', 'Sumrall', 'Lazarev', 'Wentworth-Shields', 'Mackenzie', 'Pendergrass', 'Billson', 'Teng', 'Moretti', 'Jordan', \"Ts'ao\", \"Ch'ang\", 'Obialo', 'Gray', 'Lin', 'Hopkins', 'Dobson', 'McKay', 'Revell', 'Rickards', 'Begum', 'Onyinyechukwuka', 'Zuyev', 'Nwankwo', 'Okwuadigbo', 'Chan', 'Buchi', 'Lombardi', 'Uchenna', 'Coffman', 'Alexandrova', 'Fallaci', 'Hudson', 'Stout', 'Burke', 'Chadwick', 'Lawrence', 'Bellucci', 'Harper', 'Moss', 'Avdeyeva', 'Lynton', 'Gether', 'Larionova', 'Loggia', 'Steinhoff', 'Guerra', 'Craig', 'Lazareva', 'Alderete', 'Rahman', 'McMillan', 'Pickering', 'Mirams', 'Douglas', 'Jideofor', 'Bell', 'Mairinger', 'Pagnotto', 'Feng', 'Donaldson', 'Chambers', 'Marcelo', 'Ejimofor', 'Dale', 'Pokrovsky', 'Stonebraker', 'Liang', 'Anderson', 'Christian', 'Mao', 'Sagese', 'Fleming', 'Grubb', 'Napolitani', 'Anenechi', 'Chandler', 'Howells', 'Akeroyd', 'Uwaezuoke', 'Loyau', 'Small', 'Bledsoe', 'Kao', 'Wickens', 'Wertheim', 'Jarvis', \"P'an\", 'Repina', 'Pugliesi', 'Blakey', 'Nucci', 'Higinbotham', 'Achebe', 'Dobie', 'Maccallum', 'Watkins', 'Mitchel', 'Ferdinand', 'Otitodilinna', 'Mamelu', 'Beneventi', 'Perrodin', 'Chinagorom', 'Napolitano', 'Edgar', 'Walker', 'Steele', 'Elkins', 'Toscano', 'Savage', 'Mordvinova', 'Kent', 'Cooper', 'Mazzi', 'Fisher', 'Summers', 'Brady', 'Nicholls', 'Golubov', 'Oldham', 'Kambinachi', 'Chinwemma', 'Olsen', 'Jen', 'Preston', 'Ozioma', 'Cody', 'Ponomarev', 'Milani', 'Tang', 'Romani', 'Davis', 'Onyemauchechukwu', 'Gell', 'Chiwetelu', 'Kirillova', 'Shaw', 'Okwudilichukwu', 'Onuoha', 'Muecke', 'Azubuike', 'Nnonso', 'Ashley', \"Ts'ui\", 'Kenenna', 'Beluchi', 'Williamson', 'Bobrov', 'Pitts', 'Standish', 'Cartwright', 'Johnstone', 'Nikitina', 'McElroy', 'Shen', 'Archer', 'Otutodilinna', 'Denisov', 'Owens', \"P'eng\", 'Verco', 'Bergamaschi', 'Outtrim', 'Hou', 'Galkin', 'Echezonachukwu', 'Munro', 'Ball', 'Virgo', 'Tao', 'Perez', 'Fraser', 'Alley', 'Hooper', 'Rice', 'Cox', 'Ikenna', 'Alexander', 'Piazza', 'Ni', 'Harker', 'Chiabuotu', 'Kuo', 'Gallagher', 'Zhirov', 'Lloyd', 'Palmer', \"Ch'eng\", 'Avent', 'Trentini', 'Koehler', 'Okoli', 'Nwokezuike', 'Artemiev', 'Esposito', 'Abbie', 'Averyanov', 'Unaipon', 'Clamp', 'Lim', 'Wan', 'Pettit', 'Baresi', 'Newbery', 'Iheanacho', 'Landry', 'McGregor', 'Pirogov', 'Oguejiofor', 'Ugochukwu', 'Rohu', 'Cary', \"O'Loghlen\", 'Quinn', 'Page', 'Stanley', 'Bednall', 'She', 'May', 'Seabrook', 'Herrera', 'Kincaid', 'Sleeman', 'Artemieva', 'Barwell', 'Wright', 'Moore', 'Sung', 'Mello', 'Mistry', 'Chukwukadibia', 'Zikoranachidimma', 'Oluchukwu', 'Rivera', 'Niu', 'Bennett', 'Wollstonecraft', 'Thomsen', 'Chinwendu', 'James', 'Lamb', 'Olejuru', 'Chiawuotu', 'Yeates', 'Thurgood', 'Knupp', 'Baryshnikov', 'Shephard', 'Avdeeva', 'Hsu', 'Buchanan', 'Yeh', 'Palazzi', 'Y?an', 'Schofield', 'Wall', 'Blackburn', 'Wickham', 'Bird', 'Brizendine', \"Ch'in\", 'Yusupov', 'Jibunoh', 'Wilder', 'Nepean', 'McNess', 'Coles', 'Benson', 'Gilbert', 'Wilhelm', 'Sinclair', 'Buckner', 'Padovesi', 'Palerma', 'Pan', 'Kenniff', 'Spencer', 'Lees', 'David', 'Hsing', 'Ginn', 'Sozonov', 'Manfrin', 'Artamonova', 'Hansen', 'Larsen', 'Owen', 'Murphy', 'Ekechukwu', 'Ayers', 'Sanders', 'Eberechukwu', 'Bardin', 'Talbot', 'Goold', 'Zikoranaudodimma', 'Garner', 'Naylor', 'Fulton', 'McCaffrey', 'Zuev', 'Fabro', 'Chatfield', 'Volkova', 'Abramovich', 'Chien', 'Timms', 'Williford', 'Hamilton', 'Su', 'Akobundu', 'Chukwuebuka', 'Lampungmeiua', 'Kline', 'Riggs', 'Davison', 'Ingram', 'Dilke', 'Gibson', 'Iadanza', 'Hebert', 'Jamieson', 'Chiganu', 'Burgess', 'Woods', 'Bluett', 'Chapman', 'Andrejew', 'Spyer', 'Philip', 'Perry', 'Fokine', 'Mackay', 'Maslova', 'McLean', 'Thompson', 'Tisdall', 'Onochie', 'Mironova', 'Ndubueze', 'Stephenson', 'Golubev', 'Mullan', 'Glover', 'Northey', 'Howarde', 'Colman', 'Butcher', 'Wilkie', 'Bray', 'Ann', 'Souter', 'Medvedeva', 'Onwudiwe', 'Ferrari', 'Hazon', 'Hardy', 'Dickson', 'Holden', 'Doherty', 'Samuel', 'Malloy', 'Fitts', 'Yefimova', 'Abramov', 'Demuth', 'Lawless', 'Brooks', 'Ignatyeva', 'Balmain', 'Ecuyer', 'Li Fonti', 'Despeissis', 'Williams', 'Hancock', 'Wilkins', 'Longo', 'Mancini', 'Winter-Irving', 'Stewart', 'Murray', 'Rischbieth', 'Otutodilichukwu', 'Thomas', 'Whitworth', 'Trentino', 'McMasters', 'Alekseyeva', 'Baranova', 'Yobachi', 'Sorokina', 'Ervin', 'Vance', 'Noble', 'Milanesi', 'Parkin', 'Cremonesi', 'Docherty', 'Ugonna', 'Bevan', \"O'Neill\", 'Pham', 'Osinachi', 'Muravyov', 'Igwebuike', 'Zack', 'Chidiegwu', 'Lucchesi', 'Yudin', 'Wade', 'Septimus', 'Hargraves', 'Sidorov', 'Bunton', 'Conti', 'Sims', 'Carter', 'Dumetolisa', 'Peng', 'Drake-Brockman', 'Tretiakov', 'Lai', 'Justice', 'Osonduagwuike', 'Ewing', 'Tsou', 'Ubanwa', 'Kapustin', 'Nnamutaezinwa', 'Ferri', 'Amechi', 'Kirk', 'Griffin', 'Longstaff', 'McWilliam', 'Coffee', 'Creswell', 'Dodds', 'Ewen', 'Boniwell', 'Vasilieva', 'Kwemto', 'Bocharova', 'Morres', 'Vogel', \"T'an\", 'Wisdom', 'Shahan', 'Bryant', 'Hayward', 'Liu', 'Greece', 'Norman', 'Chukwudi', 'Fedorov', 'Reid', 'Wofford', 'Stephens', 'Frolov', 'Fields', 'Suffolk', 'Judd', 'Degtyarev', 'Kinlaw', 'Omeokachie', 'Gorbunova', 'Tikhonov', 'Campa', 'Donoghue', 'Tuan', 'Baxter', 'Rogers', 'Byrne', 'Aitken', 'Macintyre', 'Simpson', 'Praed', 'Laurens', 'Bykov', 'Vorobyova', 'Pirogova', 'Sturt', 'Panicucci', 'Siciliani', 'Lucchese', 'Swaim', 'Quinones', 'Ludowici', 'Larson', 'Landman', 'K?', 'Alexeyeva', 'Chukwualuka', 'McCall', 'Okeke', 'Iloabuchi', 'Nebechukwu', 'Diribe', 'Macgroarty', 'Artemova', 'Kelly', 'Reilly', 'Ojiofor', 'Shelton', 'Lange', 'Hovell', 'Espinosa', 'Barbour', 'Ozerova', 'Ulyanova', 'Steiner', 'Akabueze', 'Aleksandrova', 'Griffiths', 'McNeil', 'Bruno', 'Okorie', 'Moen', 'McGuigan', 'Fancher', 'Matthews', 'Kaeppel', 'Yudina', 'Jamison', 'Hardiman', 'Woodard', 'Chienezie', 'Chineze', 'Buckland', 'Flannery', 'Payne', 'Vincent', 'Pearce', 'Riley', 'Honore', 'Macarthur', 'Gould', 'Medvedev', 'Sholes', 'Rolon', 'Bligh', 'Lamble', 'Jose', 'Howard', 'Onwuamaeze', \"D'Albertis\", 'Nwachukwu', 'Simpkinson', 'Conway', 'Maslow', 'Swadling', 'Gallo', 'Onyemachukwu', 'Samoylova', 'Leak', 'Frost', 'Warner', 'Ifeatu', 'Fan', 'Whiddon', 'Onyekachukwu', 'Ermakova', 'Marino', 'Onyemere', 'Everingham', 'Huie', 'Crowther', 'Skelton', 'Giordano', 'Bateson', 'Elizabeth', 'Serrano', 'Willis', 'Mashman', 'Tu', 'Romano', 'Goliwe', 'Chiemeka', 'Kellway', 'Sopuluchi', 'Spitzer', 'Potter', 'Kovalyova', 'Miah', 'Builder', 'Baddeley', 'Todd', 'Obiajulu', 'Farmer', 'Ignatieff', 'Okonkwo', 'Dore', 'Bazarova', 'Burn', 'Andreyev', 'Nock', 'Kelley', 'Wilson', 'McFarland', 'Cisneros', 'Borchgrevink', 'Rozhkova', 'Veltri', 'Golibe', 'Udinesi', 'Curtis', 'Hayden', 'Green', 'Gough', 'Bates', 'Kharlamov', 'Ferguson', 'Le Grand', 'Valdez', 'Godfrey', 'Robson', 'Yevdokimova', 'Colombo', 'Akubundu', 'Francis', 'Rhodes', 'Y?', 'Burgmann', 'Macvitie', 'Townsend', 'Pope', 'Jensen', 'Thomson', 'Chiazagomekpele', 'Ozuluonye', 'Fang', 'Horton', 'Schiavone', 'Fiorentino', 'Butusov', 'Wang', 'Alexeieva', 'Vinogradova', 'Bage', 'Naquin', 'Schroeder', 'Swearingen', 'Kozlova', 'Nekrasov', 'Olague', 'Holt', 'Davila', 'Giles', \"O'Meara\", 'Chukwuraenye', 'Tipton', 'Morey', 'Afamefuna', 'Ibbott', 'Law', 'Chinedum', 'Kruglov', 'Stone', 'Wiley', 'Chiagoziem', 'Chukwukere', 'Lee', 'Theus', 'Jennings', 'Parker', 'Patterson', 'Ofodile', 'Nash', 'Brenan', 'Obidimkpa', 'Terry', 'Spring', 'Mahmood', 'Amaechi', 'Foxall', 'Bentley', 'Baird', 'Henry', 'Rocher', 'Komar', 'Loewenthal', 'Aliyeva', 'Montes', 'Tyndall', 'Bailey', 'Onyekaozulu', 'Christmas', 'Genovesi', 'Ellis', 'Onuchukwu', 'Quaife', 'Holder', 'Lahti', 'Perkins', 'Hayes', 'Rizzo', 'Krylov', 'Matthias', 'Mason', 'Smeaton', 'Gotch', \"O'Toole\", 'Ledford', 'Alaniz', 'Saunders', 'Streeter', 'Barclay', 'Otitodilichukwu', 'Wheare', 'Soto', 'Bogle', 'Grimmett', 'Webb', 'Nwokeocha', 'Olisaemeka', 'Yobanna', 'Trevisan', 'Knox', 'Moyes', 'Beavers', 'Tretiakova', 'Aikenhead', 'Cran', 'Golubova', 'McElyea', 'Rosas', 'Phillips', 'Morris', 'Pavlova', 'Yamamoto', 'Zaitsev', 'Cawker', 'Froggatt', 'Gorbunov', 'Mikkelsen', 'Kovalyov', 'Mbanefo', 'Enderby', 'Lira', 'Castiglione', 'Yuryeva', 'Dean', 'Vasiliev', 'Fedorova', 'Samson', 'Fenton', 'Mackey', 'Payton', 'Cowger', 'Banks', 'Fantin', 'Wong', 'Roberts', 'Lo Duca', 'Ashton', 'Melton', 'Zakharov', 'Patrick', 'DeRose', 'Vavilov', 'Browne', 'Collingridge de Tourcey', 'Korovin', 'Hammonds', 'Ward', 'Gallop', 'Gartrell', 'Oluchi', 'Barlow', 'Burgin', 'Nnaife', 'Okwudiliolisa', 'Parkes', 'Kapustina', 'Greathouse', 'Beers', 'Tretyakova', 'Costa', 'Ibezimako', 'Lumholtz', 'Mouzon', 'Ibeabuchi', 'Garnsey', 'Wildman', 'Anenechukwu', 'Plant', 'Babbage', 'Norton', 'Bogolyubov', 'Gibbons', 'Gregson', 'Speth', 'Boag', 'Grave', 'Streeten', 'Fox', 'Artemyeva', 'Gardner', 'Uwakwe', 'Bellew', 'Krichauff', 'Becker', 'Ainsworth', 'Biryukov', 'Redding', 'Inman', 'Hanson', 'Fischer', 'Chinweuba', 'Henning', 'Ogochukwu', 'Narelle', 'Bergman', 'Harrison', 'Goodman', 'Ugochukwutubelum', 'Uvarova', 'Innes', 'Craigie', 'Onyekachi', 'Pethard', 'Obielumani', 'Emery', 'Dufresne', 'Vial', 'Pruneda', 'Neumann', 'Yobachukwu', 'Hess', 'Anayolisa', 'Zhou', 'Bustard', 'Ngozichukwuka', 'Lane', 'Davy', 'Barrera', 'Hall', 'Lysaght', 'Kelechi', 'Chikezie', 'Dreyer', 'Short', 'Hunt', 'Kibby', 'Ramos', 'Keeley', 'Farrar', 'Greenhalgh', 'Odili', 'Kolesnikov', 'Rutherford', 'Mendes', 'Bronner', 'Meany', 'Le Gallienne', 'Wheeler', 'Christie', 'Favors', 'Vida', 'Wayn', 'Nuttall', 'McEwan', 'Holman', 'Bazhenov', 'Kemp', 'Ebelegbulam', 'Tseng', 'Yermakov', 'Chukwunonso', 'Dawson', 'Ifeanyichukwu', 'Musgrove', 'Boulger', 'Gow', 'Robe', 'Bibi', 'Arcuri', 'Muriel', 'MacDevitt', 'Chijindum', 'Nott', 'Lei', 'Sheets', 'Tokaryev', 'Unwin', 'Frater', 'Vanmeter', 'Rearick', 'Glenny', 'Marks', 'Trout', 'Morley', 'Somadina', 'Chieloka', 'Chioke', 'Kovalev', 'Baranov', 'Bidencope', 'De Bernales', 'Cashin', 'Seppelt', \"O'Connor\", 'McGuirk', 'Ruth', 'Aksenov', 'Meng', 'Nwoye', 'Aksyonova', 'Hammer', 'Abbott', 'Davydova', 'Nkemjika', 'Mario', 'Long', 'Nelson', 'Thornton', 'Warlow-Davies', 'Champion', 'William', 'Ozoemena', 'Archambault', 'Udegbulam', 'Greene', 'Blinova', 'De Garis', 'Holmwood', 'Chidubem', 'Randall', 'Leach', 'Light', 'Holloway', 'Nwebube', 'Chibueze', 'Lanford', 'Anthony', 'Myers', 'Davey', 'Chikere', 'Hs?eh', 'Witt', 'Kazantseva', 'Bowhay', 'Beyer', 'Fries', 'Connely', 'Connolly', 'Fomin', 'Chamberlain', 'Barber', 'Zimmer', 'Brazenor', 'Caldwell', 'Yirawala', 'Tokareva', 'Castella', 'Du Cane', 'Woronoff', 'Onodugoadiegbemma', 'Darling', 'Ponomaryov', 'Prokhorova', 'Blacklock', 'Sazonova', 'Henty', 'Azuka', 'Brock', 'Bulgakov', 'Lord', 'Uspenskaya', 'Powell', 'McChesney', 'Yuriev', 'Lablanc', 'Dodd', 'Dillon', 'Hoelscher', 'Udokamma', 'Sinnett', 'Chimaijem', 'Porter', 'Younger', 'Nwagugheuzo', 'Drake', 'Hanna', 'Loftus', 'Chidalu', 'Iredale', 'Padilla', 'Ibragimova', 'Nakayama', 'Gardener', 'Aksenova', 'Kudryashova', 'Hart', 'Kruglova', 'Shaffer', 'Laurie', 'Whitfield', 'Rioux', 'Matveyev', 'Nkemdirim', 'Brim', 'Soubeiran', 'Helena', 'Macdonald', 'Chiekwugo', 'Weller', 'Bess', 'Randell', 'Randolph', 'Hurst', 'Montalvo', 'Kosisochukwu', 'Vigano', 'Windradyne', 'Curnow', 'De Neeve', 'Ebelechukwu', 'Keating', 'Shearston', 'Arnold', 'Chao', 'Zhdanova', 'Fetherstonhaugh', 'Severson', 'Speight', 'Greenwalt', 'Grover', 'Muse', 'Marsden', 'Dennis', 'Nixon', 'Rivers', 'Sochima', 'Heydon', 'Holland', 'Debellis', 'Kibble', 'Lori', 'Enemuo', 'Nebeolisa', 'Chikwado', 'Yates', 'Watt', 'Lavrov', 'Korovina', 'Manning', 'Ingrassia', 'Langdon', 'Goddard', 'Zubareva', 'Newsom', 'Shoobridge', 'Fyodorova', 'Solomon', 'Layh', 'John', 'Slattery', 'Daniels', 'Chiemenam', 'Wanliss', 'Eames', 'Kenyon', 'Parry', 'Arnott', 'Steere', 'Dickinson', 'Evseyev', 'Ulyanov', 'Kazakova', 'Hannaford', 'Mahon', 'Miles', 'Voss', 'Colebatch', 'Chikelu', 'Allan', 'Yefremova', 'Garran', 'Nkemdilim', 'Rubensohn', 'Iqbal', 'Dyer', 'Lyons', 'Namatjira', 'Leibius', 'Coppin', 'Gerasimova', 'Humffray', 'Degtyaryov', 'Cawthorne', 'Khan', 'Iroawuchi', 'Bottrill', 'Jones', 'Sanford', 'Chimaobim', 'Jowers', 'Kirsova', 'Cockrum', 'Greaves', 'Reeves', 'Nnamdi', 'Charlton', 'Marsh', 'Pottinger', 'Buckley', 'Folliero', 'Jessop', 'Hodge', 'Ignatiev', 'Mansom', 'Komarova', 'Yu', 'Sutton', 'Hyde', 'Smalley', 'Barton', 'Horrocks', 'Frye', 'Mellor', 'Meredith', 'Chinomso', 'Chimaoke', 'Winters', 'Hawthorn', 'Hawdon', 'Joslin', 'Bidwill', 'Tate', 'Neal', 'Fulks', 'Siciliano', 'Ositadimma', 'Kazantsev', 'Dolgorukova', 'Singh', 'Shipton', 'Rivas', 'Hoolan', 'Pepper', 'Abramowitz', 'Abazu', 'Harriman', 'Frankland', 'Kwemtochukwu', 'To Rot', 'Lear', 'Winter', 'Hughes-Jones', 'Estrada', 'Heard', 'Efremova', 'Morphett', 'Lenhardt', 'McMorran', 'Phelan', 'Hotchin', 'Aksyonov', 'McGarry', 'Akhtar', 'McDaniels', 'Tennant', 'Donaghy', 'Tobenna', 'Vicars', 'Vessels', 'Heller', 'Dunn', 'Vasilyeva', 'Mollison', 'Aiken', 'Brabyn', 'Traeger', 'Ekwueme', 'Chinwenma', 'Estep', 'Mishina', 'Lavrentiev', 'Kilgour', 'Sheppard', 'Nnanna', 'Norris', 'Chidiebere', 'Okwukwe', 'Elliott', 'Walsh', 'Mahomed', 'Bogdanov', 'Moysey', 'Angel', 'Toosey', 'Hassall', 'Poninski', 'Bonham', 'Bold', 'Izmailov', 'Valentin', 'McIver', 'Fishbourne', 'Chukwueloka', 'Real', 'Odell', 'Enticknap', 'Mann', 'Adams', 'Hirst', 'Horan', 'Cumbrae-Stewart', 'Kinney', 'Nina', 'Mort', 'Martinez', 'Vasilyev', 'Lacross', 'Maughan', 'Tochukwu', 'Slate', 'Chiebuka', 'Berry', 'Boylan', 'Warren', 'Liston', 'Mazure', 'Rudduck', 'Darwin', 'Tomlinson', 'Coates', 'Hickey', 'Stobie', 'Drakeford', 'Bermudez', 'Wyatt', 'Blackwood', 'Storey', 'Glasgow', 'Crotty', 'Hysell', 'Compton', 'See', 'Threatt', 'Davies', 'Matlock', 'Chiedozie', 'Adamson', 'Mishin', 'Bull', 'Serra', 'Summerville', 'Astorga', 'Blesing', 'Nevzorova', 'Sheehan', 'McElhone', 'Chigbogu', 'Tilley', 'McCartney', 'Badgery', 'Zarate', 'Congreve', 'Hayslett', 'Loving', 'Ugonnatubelum', 'Corbett', 'Eiland', 'Labrador', 'Dettmann', 'Hope', 'Ives', 'Brierly', 'Rapuokwu', 'Senior', 'Garmon', 'Biryukova', 'Hutcheon', 'Bateman', 'Haugh', 'Micklem', 'Kegley', 'Valenzuela', 'Fomina', 'Dixon', 'Belov', 'Cross', 'Cullen', 'Rudd', 'Gidney', 'Dalton', 'Hartzler', 'Lambert', 'Game', 'Haynes', 'Jimenez', 'Pharr', 'Jerger', 'Ramsden', 'Jowett', 'Venables', 'Monnier', 'Gadsden', 'Oster', 'Chizoba', 'Peyser', 'Seleznev', 'Alleyne', 'Zikoranachukwudimma', 'Ejikemeifeuwa', 'Rickard', 'Andreev', 'Shand', 'Stehle', 'Belonwu', 'Baker', 'Garcia', 'Field', 'Jefferies', 'Lockyer', 'Torreggiani', 'Richards', 'Herbert', 'Andreyeva', 'Bowen', 'Fowler', 'Lockett', 'Phelps', 'Frederick', 'Carlson', 'Mbadiwe', 'Sabbatini', 'Ewers', 'Hannam', 'Mofflin', 'Ifeanacho', 'Maitland', 'Pollard', 'Brigstocke', 'Gboliwe', 'Seleznyova', 'Joseph', 'Salier', 'Evdokimov', 'Ponomaryova', 'Grosse', 'Belbin', 'Titheradge', 'Hobbs', 'Beggs', 'Luffman', 'Evseev', 'Hagins', 'Kirwan', 'Milligan', 'Royster', 'Gouger', 'Ignatyev', 'Munz', 'Paling', 'Clancy', 'Rios', 'Onyemauchechi', 'Nkemakonam', 'Kirillov', 'Stiles', 'Gaffney', 'Tsui', 'Armit', 'Ramsbotham', 'Scannell', 'Edman', 'Shaver', 'Coupp', 'Bezrukova', 'Cohn', 'Lay', 'Schmidt', 'Hussey', 'Macfarlan', 'Szabados', 'McKelvey', 'McConnell', 'Iheatu', 'Winifred', 'Holmes', 'Riddle', 'McClemans', 'Basedow', 'Nwora', 'Howey', 'Kramer', 'Reynolds', 'Herrin', 'Newland', 'Demaine', 'Harewood', 'Bischof', 'Uren', 'Ruggiero', 'Wilding', 'Yashina', 'Yevseyev', 'Maslov', 'Sullivan', 'Allsop', 'Castles', 'Colbert', 'Chimezie', 'Daluchi', 'Sheffield', 'Dyson', 'Onwuka', 'Flores', 'Nicoll', 'Waters', 'Raynor', 'Eberegbulam', 'Micco', 'Avdeev', 'Bremer', 'Gadsdon', 'Hicks', 'Logan', 'Weber', 'Schnaars', 'Algarin', 'Metcalf', 'Lupton', 'Ibeamaka', 'Rueda', 'Madueke', 'Torres', 'Chukwubuikem', 'Semmens', 'Bogdanova', 'Corser', 'McCardle', 'Radcliffe-Brown', 'Chukwumaobim', 'Cardus', 'Whitehouse', 'McCulloch', 'Koo', 'Woolnough', 'Vinogradov', 'Snider', 'Isayeva', 'Moreno', 'Gill', 'Vaguine', 'Toomey', 'Bonwick', 'Middleton', 'Vale', 'Arkwookerum', 'Lujan', 'Gannon', 'Romero', 'Onwuamaegbu', 'Peacock', 'Barese', 'Nnaemeka', 'Efimov', 'Maynard', 'Zotova', 'Hannah', 'Cartagena', 'Victor', 'Krawczyk', 'Abel', 'Cavill', 'Renwick', 'Linton', 'Langlands', 'Sykes', 'Kryukov', 'Donnelly', 'Boucaut', 'Silva', 'Iweobiegbunam', 'Zito', 'Edmondstone', 'Georg', 'Michelides', 'Chidimma', 'Edmund la Touche', 'Belousov', 'McCane', 'Parry-Okeden', 'Aldrich', 'Shillito', 'Ikechukwu', 'Kauffmann', 'Bock', 'Brewer', 'Yermakova', 'Jacka', 'Sharp', 'Atherton', 'Cookson', 'Hort', 'Zaytseva', 'Diehl', 'Mead', 'Nicholson', 'Huddart', 'Swain', 'Brient', 'Tucker', 'Izmailova', 'Hutchinson', 'Okwuoma', 'Amadi', 'Percy', 'Floyd', 'Melendez', 'Kovaleva', 'Chukwuma', 'Gilroy', 'Hearn', 'Swanson', 'Benjamin', 'Ryrie', 'Montemayor', 'Izuchukwu', 'Herring', 'Duffy', 'Chiefo', 'Fyodorov', 'Palmerston', 'Polyakov', 'Connor', 'Chester', 'Denisova', 'Clogstoun', 'Kalinina', 'Bennet', 'Hallahan', 'Louis', 'Trouette', 'Cribb', 'Fletcher', 'Corson', 'Hinton', 'Bromby', 'Nweke', 'Batty', 'Agafonova', 'Chidumaga', 'Birk', 'Childs', 'Obioma', 'Stetson', 'Waring', 'Thao', 'Armfield', 'Panina', 'Martel', 'Buddicom', 'Walters', 'Muravyova', 'Keen', 'Liebe', 'Rogova', 'Raff', 'Kanayochukwu', 'Guerin', 'Dominguez', 'Pugh', 'Sawtell', 'Kharitonova', 'Muramats', 'Sokolov', 'Gay', 'Maurer', 'Grieve', 'Lowell', 'Philipp', 'Dynon', 'Bishop', 'Rene', 'Daigle', 'Joshua', 'Cochran', 'Bibb', 'Corran', 'Lovely', 'Plascencia', 'Zotov', 'Lynch', 'McCarthy', 'Nnabuife', 'Tinline', 'Esomchi', 'Retana', \"O'Loughlin\", 'Gorman', 'Finch', 'Reyes', 'Downie', 'Yegorov', 'Cantrell', 'Glennon', 'Yancy', 'Cruz', 'Bukowski', 'Chikwendu', 'Kharlamova', 'Diaz', 'Ross-Watt', 'Shubin', 'Sadler', 'Whittaker', 'Gratwick', 'Bovee', 'Frolova', 'Bradshaw', 'Clunie', 'Cover', 'Hodgson', 'Harvey', 'Chase', 'Aparicio', 'Udegbunam', 'Alexandrov', 'Campos', 'McKinnon', 'Burt', 'Feetham', 'Coburn', 'Yegorova', 'Corones', 'Morrice', 'Barrett', 'Tardent', 'Castillo', 'Lindsay', 'Macnamara', 'Aksakova', 'Farnsworth', 'Koch', 'Fleetwood-Smith', 'Chinonyelum', 'Montague', 'Yewen', 'Kalinin', 'Woodward', 'Iweobiegbulam', 'Burton', 'Schwartz', 'Sargent', 'Kepley', 'Lassetter', 'Iloerika', 'Michel', 'Goodwin', 'Rapuluolisa', 'Osorio', 'Barnett', 'Pike', 'Gearheart', 'Egobudike', 'Ahern', 'Anayochukwu', 'Nevels', 'Winn', 'Lopez', 'Steen', 'Pipes', 'Windsor', 'Wark', 'Allnutt', 'Pedder', 'Chialuka', 'Selwyn', 'Koger', 'Kendall', 'Elliot', 'Gratton', 'Carandini', 'Barker', 'Korff', 'Kiernan', 'Mathews', 'Macrossan', 'Illingworth', 'Menhennitt', 'Shoebridge', 'Eva', 'Howe', 'Belisario', 'Pomeroy', 'Schaffer', 'Gonzalez', 'Temple', 'Ridley', 'Slye', 'Takasuka', 'Bruche', 'Ryan', 'Abramova', 'Purdy', 'Higgins', 'Reye', 'Willoughby', 'Mayne', 'Paramor', 'Daly', 'Gorshkov', 'McClinton', 'Holbrook', 'Solomina', 'Faulk', 'Forster', 'Chamberlin', 'Buttenshaw', 'Nazarova', 'Merrett', 'Elder', 'Gunson', 'Gleeson', 'Lang', 'Eve', 'Stradford', 'Brownlow', 'Fyans', 'Creel', 'Nicolay', 'Somerville', 'Pauley', 'Goering', 'Maduabuchim', 'Linger', 'Kenechukwu', 'Learmonth', 'Fitzgerald', 'Duggan', 'Krischock', 'Binder', 'Zubarev', 'Coleman', 'Molineux', 'Duigan', 'Jobson', 'Perreault', 'Algeranoff', 'Galloway', 'Arrington', 'Kamdibe', 'Cousens', 'Hawks', 'Thynne', 'Greenwood', 'Ogle', 'Wolfe', 'Dilibe', 'Austin', 'Santiago', 'Afanasyeva', 'Priestley', 'Salmond', 'Goloubev', 'Dipietro', 'Niehaus', 'Barclay-Harvey', 'Hartung', 'Sternberg', 'Shepherd', 'Marcum', 'North', 'Whitelegge', 'Rooke', 'Horsley', 'Eskridge', 'Claiborne', 'Ibrahimov', 'Enriquez', 'Gilleland', 'Fullwood', 'Doyne', 'Rawling', 'Ankudinova', 'Balsillie', 'Worsnop', 'Buda', 'Broadhurst', 'Garrett', 'Edwards', 'Logue', 'Rechner', 'Batt', 'Trujillo', 'Ash', 'Kumm', 'Carey', 'Farber', 'Edments', 'Lindon', 'Pitcher', 'Kable', 'Kulikova', 'Navarrete', 'Huguley', 'Massie', 'Onwubiko', 'Obiora', 'Slater', 'Menkens', 'Beatham', 'Dowse', 'Griffen', 'Uvarov', 'Hussain', 'Grigoryeva', 'Gunter', 'Collee', 'Ibekwe', 'Hairston', 'Abdulov', 'Perkin', 'Bond', 'Stirling', 'Rutledge', 'Mullah', 'Candler', 'Hollis', 'Lionel', 'Serena', 'Cummins', 'Zhdanov', 'Peck', 'Gerald', 'Nebeuwa', 'Maruff', 'Knepper', 'Hand', 'Chidi', 'Maxwell', 'Berkeley', 'Kaur', 'Mountgarrett', 'Wreford', 'Bolton', 'Corrie', 'Lambie', 'Streeton', 'Pennington', 'Ansell', 'Stokes', 'Ampt', 'Wynn', 'Wagner', 'Argyle', 'Locke', 'Bullen', 'Munson', 'Cooke', 'Hawes', 'Swanton', 'Shipp', 'Jonathan', 'Hernandez', 'Highland', 'Peel', 'Herz', 'Salas', 'Laney', 'Messersmith', 'Etheridge', 'Jolly', 'Botts', 'Fink', 'Morehead', 'Balashova', 'Lowe', 'Ponce', 'Zuyeva', 'Chukwujamuike', 'Flynn', 'Klein', 'Shcherbakov', 'Sokolova', 'Mosley', 'Everett', 'Rouse', 'Burrows', 'Artyomova', 'Yermolayeva', 'Le Hunte', 'Blake', 'Sparks', 'Northern', 'Jack', 'Secombe', 'Ugorji', 'Bancks', 'Fairley', 'Boothby', 'Chukwuhaenye', 'Lock', 'Ramsey', 'Eipper', 'Fernandez', 'Yermolayev', 'Kolesnikova', 'Sharwood', 'Bufkin', 'Neitenstein', 'Sandover', 'Sergeyeva', 'Bales', 'Romilly', 'Lawson', 'Bracewell', 'Torkelson', 'Hightower', 'Levan', 'Loginov', 'Lafleur', 'Miranda', 'Simon', 'Golubeva', 'Stange', 'Milliner', 'Swinton', 'Sukhorukova', 'Combes', 'Carruthers', \"O'Loghlin\", 'Troupe', 'Deleon', 'Downer', 'Bochsa', 'Czajkowski', 'Pankhurst', 'Birdseye', 'Moon', 'Chuter', 'Nielson', 'Ajuluchukwu', 'Board', 'Leckie', 'Cayley', 'Kuykendall', 'Ukaegbulam', 'Onwuemelie', 'Clendinnen', 'Mactier', 'Lipton', 'Levy', 'Amies', 'Aliyev', 'Langler', 'Pye', 'Asher', 'Major', 'Halpern', 'Nyhan', 'Birdsall', 'Mackie', 'Vinogradoff', 'Pokrovskaya', 'Moroney', 'Spence', 'Cherkasova', 'Crocker', 'Polyakova', 'Cantamessa', 'Teakle', 'Challis', 'Dodgshun', 'Blackall', 'Schoenheimer', 'Bromley', 'Shubina', 'Kinder', 'Shepherdson', 'Burson', 'Hopwood', 'Lindeman', 'McKinley', 'Sanchez', 'Muomelu', 'McVey', 'McKissick', 'Horsfall', 'Clapp', 'MacDonnell', 'Ermakov', 'Peppin', 'Fontenot', 'Howarth', 'Gentry', 'Sunderland', 'Knorr', 'Chimaraoke', 'Frederickson', 'Pickworth', 'McGill', 'Sarratt', 'Leworthy', 'Rivero', 'Hornung', 'Barnet', 'Dennys', 'Salter', 'Lazar', 'Onyenachiya', 'McCawley', 'Teague', 'Nekrasova', 'Carroll', 'Landor', 'Wardell', 'Ali', 'Somayina', 'Ruiz', 'Waterhouse', 'Jara', \"O'Callaghan\", 'Pease', 'Lavrentyev', 'Hobson', 'Lappin', 'Travis', 'Jefferson', 'Begley', 'Levien', 'Erskine', 'Monds', 'Castro', 'Voronova', 'Dietz', 'Voronoff', 'Trevascus', 'Durant', 'Chigozie', 'Ardis', 'Butler', 'Pettry', 'Elmore', 'Voronkov', 'Garland', 'Ndubuagha', 'Duke', 'Bradbury', 'Bayley', 'Cremin', 'Gilchrist', 'Fitzpatrick', 'Pagan', 'Hendrick', 'Harding', 'Burfitt', 'Nieves', 'Bruny', 'Felix', 'Rippey', 'Converse', 'Bogolyubova', 'Remington', 'Levi', 'Bennetts', 'Vachon', 'Upjohn', 'Marcus', 'Alvares', 'McDavid', 'Brothers', 'Molle', 'Galgano', 'Raymond', 'Brodney', 'Afanasyev', 'Meagher', 'McGuffog', 'Sargood', 'Harrington', 'Lorenzen', 'Vidler', 'Allingham', 'Stelzer', 'Rubin', 'Harrell', 'Welsh', 'Sousa', 'Obijiaku', 'Mullen', 'Howell', 'Clifton', 'Rees', 'Onwughara', 'Geoghegan', 'Ilyina', 'Quezada', 'Tobeolisa', 'Akudinobi', 'Flemming', 'Azarov', 'Chill', 'Dumolo', 'Wetherspoon', 'Hampton', 'Ireland', 'Hibbins', 'Lea', 'Singleton', 'Sauve', 'Eidson', 'Melvin', 'Dawkins', 'Rita', 'Woolacott', 'Service', 'Dancy', 'Hankinson', 'Afamefula', 'Sherrod', 'Barling', 'Hobler', 'Bair', 'Drury', 'Beale', 'McMinn', 'Hajek', 'Mays', 'Swayne', 'Fennescey', 'Colon', 'Lederer', 'Cecil', 'Manners', 'Wynne', 'Disher', 'Yocum', 'Lowrie', 'Lavarack', 'Gomes', 'Gibney', 'Foran', 'Wyckoff', 'Soares', 'Kenechi', 'Becher', 'Runyon', 'Dobbs', 'Foveaux', 'Currey', 'Nicholas', 'Foster', 'Edmondson', 'Ah Mouy', 'Blue', 'Sievier', 'Watterston', 'Butters', 'Weaver', 'Earl', 'Begg', 'McNaughtan', 'Reagan', 'Bancroft', 'Band', 'Sandefur', 'Cone', 'Liardet', 'Wilkes', 'Patel', 'Howell-Price', 'Rowland', 'Barnard', 'Pendred', 'Samaniego', 'Burgos', 'Spinelli', 'Peavy', 'Lindell', 'Sorenson', 'Cockett', 'Galkina', 'Spears', 'Hardacre', 'Wakelin', 'Shah', 'Combs', 'Mayrhofer', 'Yefremov', 'Kosovich', 'Taplin', 'Yefimov', 'Hales', 'Copeland', 'Rishel', 'Larkin', 'Eddy', 'Sells', 'Bezrukov', 'St Clair', 'Lockington', 'Weston', 'Groom', 'Cambage', 'Burdekin', 'Franz', 'Morant', 'Loton', 'Sani', 'Von Doussa', 'Miracle', 'Burtch', 'McLachlan', 'Wenz', 'Kisch', 'Newman', 'Ndubuisi', 'Plummer', 'Ershova', 'Brookman', 'McBurney', 'Mickey', 'Olszewski', 'Chijioke', 'Bellasis', 'De Mestre', 'Mundy', 'Donahue', 'Verjus', 'Spaull', 'Voronina', 'Crumbley', 'Birch', 'Custance', 'Marshall-Hall', 'More', 'Bazile', 'Wardle', 'Lilly', 'Medland', 'Denman', 'Ratten', 'Abron', 'Belcher', 'Abernathy', 'Pape', 'Earle', 'Coombes', 'Hopman', 'Trejo', 'Macknight', 'Glossop', 'Chalmers', 'Picot', 'Neumayer', 'Yip', 'Ingle', 'Coffey', 'Istomin', 'Fernando', 'McClaran', 'Townsley', 'Mueller', 'Madukaife', 'Abdullah', 'Caraway', 'Loane', 'Geach', 'Charteris', 'Descoteaux', 'Crump', 'Diggs', 'Carvosso', 'Furneaux', 'Nickson', 'Highett', 'Rendall', 'Allardyce', 'Weatherford', 'Chong', 'Alvarez', 'Pritchard', 'Rawlings', 'Truscott', 'Willmore', 'Godson', 'Bitter', 'Forlonge', 'Reyna', 'Tran', 'Otoole', 'Kane', 'Isaacs', 'Timperley', 'Christopher', 'Lawley', 'Whitson', 'Wimble', 'Fermin', 'Fadden', 'Zox', 'Landseer', 'Jenks', 'Crace', 'Packham', 'Emenike', 'Nero', 'Haddon', 'Slone', 'Dann', 'Hooker', 'Kistler', 'Leason', 'Bruner', 'Rubeo', 'Claypool', 'Walpole', 'Steigrad', 'Hixson', 'Laura', 'Hendley', 'Birnie', 'Montgomery', 'Gamble', 'Chifo', 'Michael', 'Quesada', 'Wunder', 'Burlingame', 'Kesteven', 'Abrego', 'Parrott', 'Zinachukwudi', 'Keane', 'McCollum', 'Gambrell', 'Rieke', 'Cawood', 'Yelverton', 'Mault', 'Frewin', 'Royston', 'Wearing', 'Suttor', 'Catchpole', 'Siddons', 'Arbour', 'Hingston', 'Sacco', 'Robb', 'Ochoa', 'Richmond', 'Nworie', 'Wentcher', 'Hayes-Williams', 'Cairns', 'Schatz', 'Stanton', 'Ramirez', 'Bryan', 'Mullawirraburka', 'Chubb', 'Huggins', 'Cowen', 'Kaleski', 'Sugden', 'Beck', 'Beam', 'Haworth', 'Guidry', 'Maher', 'Rapuluchukwu', 'Cyril', 'Laidley', 'McNeill', 'Kentish', 'Persse', 'Chukwujekwu', 'Ham', 'Paten', 'Esquivel', 'Sidorova', 'Santana', 'Mironov', 'Ruse', 'Palfreyman', 'Webster', 'Cardell', 'Lennox', 'Meldrum', 'Vidal', 'Veale', 'Kershaw', 'Vanzetti', 'Boone', 'Nagy', 'Lehr', 'Upchurch', 'Woodhouse', 'Toth', 'Ingamells', 'Overby', 'Chifley', 'Rodriguez', 'Kingsley', 'Gosnell', 'Gearhart', 'Seccombe', 'Rounsevell', 'Stoneman', 'Moody', 'Keldie', 'Defalco', 'Tillman', 'Beede', 'Sadlier', 'Bozeman', 'Shelby', 'Marian', 'Fane', 'Caffyn', 'Dahlenburg', 'Olson', 'Andersen', 'Mackinlay', 'Norriss', 'Mott', 'Fokina', 'Boan', 'Topp', 'Burgoyne', 'Gebhart', 'Tudawali', 'Maconochie', 'Plumb', 'Benford', 'Cobb', 'Macadam', 'Tychonoff', 'Urban', 'Lascelles', 'Mack', 'Sneddon', 'Hopetoun', 'Faria', 'Marquez', 'Barnhill', 'Ogg', 'Wells', 'Calzada', 'Gresswell', 'Aguirre', 'Morales', 'Moffitt', 'Weigel', 'Ohearn', 'Munroe', 'Trumbull', 'Crist', \"O'Kane\", 'Lorimer', 'McDowell', 'Root', 'Saad', 'Corby', 'Dwyer', 'Flannagan', 'Sturdee', 'Hull', 'Vagin', 'Mach', 'MacPherson', 'Parks', 'Edith', 'Lajoie', 'Torode', 'Salinas', 'Cleveland', 'Kashiwagi', 'Aldridge', 'Burbidge']\n",
      "\n",
      "Уникальные значения в ячейках для столбца geography\n",
      "['France', 'Spain', 'Germany']\n",
      "\n",
      "Уникальные значения в ячейках для столбца gender\n",
      "['Female', 'Male']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lister = ['surname', 'geography', 'gender']\n",
    "for col in lister:\n",
    "    print(f'Уникальные значения в ячейках для столбца {col}')\n",
    "    print(list(df[col].unique()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Вывод: Неверных значений в ячейках нет. Так же видим, что география охвата клиентов включает в себя только три страны: Франция, Испания, Германия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исследуем столбец tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     952\n",
       "2.0     950\n",
       "8.0     933\n",
       "3.0     928\n",
       "5.0     927\n",
       "7.0     925\n",
       "4.0     885\n",
       "9.0     882\n",
       "6.0     881\n",
       "10.0    446\n",
       "0.0     382\n",
       "Name: tenure, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tenure'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пустые столбцы занчемем -1 и посмотрим что это за записи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>surname</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_products</th>\n",
       "      <th>has_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15589475</td>\n",
       "      <td>Azikiwe</td>\n",
       "      <td>591</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140469.38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>15766205</td>\n",
       "      <td>Yin</td>\n",
       "      <td>550</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>103391.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90878.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>15768193</td>\n",
       "      <td>Trevisani</td>\n",
       "      <td>585</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>146050.97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86424.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>15702298</td>\n",
       "      <td>Parkhill</td>\n",
       "      <td>655</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>125561.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164040.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>15651280</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>742</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>136857.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84509.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944</th>\n",
       "      <td>15703923</td>\n",
       "      <td>Cameron</td>\n",
       "      <td>744</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>190409.34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138361.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9956</th>\n",
       "      <td>15707861</td>\n",
       "      <td>Nucci</td>\n",
       "      <td>520</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>85216.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117369.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>15642785</td>\n",
       "      <td>Douglas</td>\n",
       "      <td>479</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117593.48</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113308.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>15586914</td>\n",
       "      <td>Nepean</td>\n",
       "      <td>659</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>123841.49</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96833.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>909 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customer_id    surname  credit_score geography  gender  age  tenure  \\\n",
       "30       15589475    Azikiwe           591     Spain  Female   39    -1.0   \n",
       "48       15766205        Yin           550   Germany    Male   38    -1.0   \n",
       "51       15768193  Trevisani           585   Germany    Male   36    -1.0   \n",
       "53       15702298   Parkhill           655   Germany    Male   41    -1.0   \n",
       "60       15651280     Hunter           742   Germany    Male   35    -1.0   \n",
       "...           ...        ...           ...       ...     ...  ...     ...   \n",
       "9944     15703923    Cameron           744   Germany    Male   41    -1.0   \n",
       "9956     15707861      Nucci           520    France  Female   46    -1.0   \n",
       "9964     15642785    Douglas           479    France    Male   34    -1.0   \n",
       "9985     15586914     Nepean           659    France    Male   36    -1.0   \n",
       "9999     15628319     Walker           792    France  Female   28    -1.0   \n",
       "\n",
       "        balance  num_products  has_card  active_member  estimated_salary  \\\n",
       "30         0.00             3         1              0         140469.38   \n",
       "48    103391.38             1         0              1          90878.13   \n",
       "51    146050.97             2         0              0          86424.57   \n",
       "53    125561.97             1         0              0         164040.94   \n",
       "60    136857.00             1         0              0          84509.57   \n",
       "...         ...           ...       ...            ...               ...   \n",
       "9944  190409.34             2         1              1         138361.48   \n",
       "9956   85216.61             1         1              0         117369.52   \n",
       "9964  117593.48             2         0              0         113308.29   \n",
       "9985  123841.49             2         1              0          96833.00   \n",
       "9999  130142.79             1         1              0          38190.78   \n",
       "\n",
       "      exited  \n",
       "30         1  \n",
       "48         0  \n",
       "51         0  \n",
       "53         1  \n",
       "60         0  \n",
       "...      ...  \n",
       "9944       0  \n",
       "9956       1  \n",
       "9964       0  \n",
       "9985       0  \n",
       "9999       0  \n",
       "\n",
       "[909 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_1 = df.fillna(-1.0)\n",
    "display(df_1[df_1['tenure'] == -1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим гистограммы по этим пустым ячейкам и сравним с гистограммами с похожим количеством строк при tenure = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['age'][df['tenure'] == 1.0] , range = (0, 100), bins=100, label = 'df')\n",
    "plt.hist(df_1['age'][df_1['tenure'] == -1.0] , range = (0, 100), bins=100, label = 'df_1')\n",
    "plt.ylabel('Частотность')\n",
    "plt.xlabel('Возраст')\n",
    "plt.legend()\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['credit_score'][df['tenure'] == 1.0] , range = (0, 1000), bins=100, label = 'df')\n",
    "plt.hist(df_1['credit_score'][df_1['tenure'] == -1.0] , range = (0, 1000), bins=100, label = 'df_1')\n",
    "plt.ylabel('Частотность')\n",
    "plt.xlabel('Возраст')\n",
    "plt.legend()\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из гистограмм видно что данные с пустыми ячейками весьма похожи на данные клиентов второго года, то есть данные с пустыми tenure содержат некий похожий срез данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень хорошо бы узнать у разработчиков, что это за пустые ячейки, но судя по анализу и тому, что новых клиентов при  tenure = 0.0    всего 382, и видим тенденцию уменьшения клентов с годами то вероятно эти пустые ячейки - это новые клиенты, и заполним их нулями, так же можно будет сразу преобразовать в тип данных int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tenure'] = df['tenure'].fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customer_id       10000 non-null  int64  \n",
      " 1   surname           10000 non-null  object \n",
      " 2   credit_score      10000 non-null  int64  \n",
      " 3   geography         10000 non-null  object \n",
      " 4   gender            10000 non-null  object \n",
      " 5   age               10000 non-null  int64  \n",
      " 6   tenure            10000 non-null  int64  \n",
      " 7   balance           10000 non-null  float64\n",
      " 8   num_products      10000 non-null  int64  \n",
      " 9   has_card          10000 non-null  int64  \n",
      " 10  active_member     10000 non-null  int64  \n",
      " 11  estimated_salary  10000 non-null  float64\n",
      " 12  exited            10000 non-null  int64  \n",
      "dtypes: float64(2), int64(8), object(3)\n",
      "memory usage: 1015.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1291\n",
       "1      952\n",
       "2      950\n",
       "8      933\n",
       "3      928\n",
       "5      927\n",
       "7      925\n",
       "4      885\n",
       "9      882\n",
       "6      881\n",
       "10     446\n",
       "Name: tenure, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tenure'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Вывод: Все необходимые преобразования таблицы проделаны, можно приступать к дальнейшей работе с данными для создания моделей предсказаний."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаление столбцов из таблицы, не влияющих на обучение моделей предсказаний"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для создания модели предсказаний не важны следующие столбцы: customer_id, surname , так как они никак не должны влиять на то: \"Ушел ли клент или остался в банке\"... Если конечно отбросить возможность влияния имени на решения и жизнь человека."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['customer_id', 'surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   credit_score      10000 non-null  int64  \n",
      " 1   geography         10000 non-null  object \n",
      " 2   gender            10000 non-null  object \n",
      " 3   age               10000 non-null  int64  \n",
      " 4   tenure            10000 non-null  int64  \n",
      " 5   balance           10000 non-null  float64\n",
      " 6   num_products      10000 non-null  int64  \n",
      " 7   has_card          10000 non-null  int64  \n",
      " 8   active_member     10000 non-null  int64  \n",
      " 9   estimated_salary  10000 non-null  float64\n",
      " 10  exited            10000 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразование категориальных данных в числовые, метод OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe_drop = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_products</th>\n",
       "      <th>has_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_score  age  tenure    balance  num_products  has_card  \\\n",
       "0           619   42       2       0.00             1         1   \n",
       "1           608   41       1   83807.86             1         0   \n",
       "2           502   42       8  159660.80             3         1   \n",
       "3           699   39       1       0.00             2         0   \n",
       "4           850   43       2  125510.82             1         1   \n",
       "\n",
       "   active_member  estimated_salary  exited  geography_Germany  \\\n",
       "0              1         101348.88       1                  0   \n",
       "1              1         112542.58       0                  0   \n",
       "2              0         113931.57       1                  0   \n",
       "3              0          93826.63       0                  0   \n",
       "4              1          79084.10       0                  0   \n",
       "\n",
       "   geography_Spain  gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ohe_drop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот у нас и нет более категориальных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Массштабирование признаков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler #импортируем метод массштабирования\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['credit_score', 'age', 'tenure', 'balance', 'num_products', 'has_card', 'active_member', 'estimated_salary', 'exited', 'geography_Germany', 'geography_Spain', 'gender_Male']\n"
     ]
    }
   ],
   "source": [
    "lister = list(df_ohe_drop.columns)\n",
    "print(lister)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['credit_score', 'age', 'tenure', 'balance',\n",
    "           'num_products', 'has_card', 'active_member',\n",
    "           'estimated_salary']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(df_ohe_drop[numeric])\n",
    "df_ohe_drop[numeric] = scaler.transform(df_ohe_drop[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_products</th>\n",
       "      <th>has_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.326221</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-0.817441</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.440036</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>-1.138838</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.536794</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>1.110941</td>\n",
       "      <td>1.333053</td>\n",
       "      <td>2.527057</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>0.240687</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501521</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-1.138838</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.108918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.063884</td>\n",
       "      <td>0.388871</td>\n",
       "      <td>-0.817441</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-0.365276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_score       age    tenure   balance  num_products  has_card  \\\n",
       "0     -0.326221  0.293517 -0.817441 -1.225848     -0.911583  0.646092   \n",
       "1     -0.440036  0.198164 -1.138838  0.117350     -0.911583 -1.547768   \n",
       "2     -1.536794  0.293517  1.110941  1.333053      2.527057  0.646092   \n",
       "3      0.501521  0.007457 -1.138838 -1.225848      0.807737 -1.547768   \n",
       "4      2.063884  0.388871 -0.817441  0.785728     -0.911583  0.646092   \n",
       "\n",
       "   active_member  estimated_salary  exited  geography_Germany  \\\n",
       "0       0.970243          0.021886       1                  0   \n",
       "1       0.970243          0.216534       0                  0   \n",
       "2      -1.030670          0.240687       1                  0   \n",
       "3      -1.030670         -0.108918       0                  0   \n",
       "4       0.970243         -0.365276       0                  0   \n",
       "\n",
       "   geography_Spain  gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ohe_drop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделим исходные данные на обучающую, валидационную и тестовую выборки без стратификации и баланса классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на следующие части:\n",
    "\n",
    "* 60% - тренировочные данные,\n",
    "* 20% - валидационные данные,\n",
    "* 20% - тестовые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = np.split(df_ohe_drop.sample(frac=1, random_state=12345),[int(.6*len(df)), int(.8*len(df))])\n",
    "# первый аргумент случайно перемешивает таблицу, второй разбивает на 60 и от 60 до 100%\n",
    "# и далее еще на два от 60 до 80 и от 80 до 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 12)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 12)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 12)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = train.drop(['exited'], axis=1)\n",
    "target_train = train['exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_valid = validate.drop(['exited'], axis=1)\n",
    "target_valid = validate['exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = test.drop(['exited'], axis=1)\n",
    "target_test = test['exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследуем качество F1-меры разных моделей на данных без стратификации, меняя гиперпараметры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем все необходимые модули:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель решающего дерева:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая depth: 7\n",
      "F1-мера наилучшей модели на валидационной выборке: 0.5446293494704992\n",
      "roc_auc наилучшей модели на валидационной выборке: 0.8083453252944778\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "roc_auc = 0\n",
    "best_depth = 0\n",
    "for depth in range(1, 20):\n",
    "    model_tree = DecisionTreeClassifier(random_state=12345, max_depth=depth) # обучите модель с заданной глубиной дерева\n",
    "    model_tree.fit(features_train, target_train) # обучите модель\n",
    "    predictions = model_tree.predict(features_valid) # получите предсказания модели\n",
    "    result = f1_score(target_valid, predictions) # посчитайте качество модели\n",
    "    probabilities_valid = model_tree.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    if result > best_result:\n",
    "        best_model = model_tree# сохраните наилучшую модель\n",
    "        best_result = result\n",
    "        roc_auc = auc_roc\n",
    "        best_depth = depth\n",
    "print(\"Наилучшая depth:\", best_depth)\n",
    "print(\"F1-мера наилучшей модели на валидационной выборке:\", best_result)\n",
    "print(\"roc_auc наилучшей модели на валидационной выборке:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая n_estimators: 7\n",
      "Наилучшая depth: 16\n",
      "F1-мера наилучшей модели на валидационной выборке: 0.5529411764705883\n",
      "roc_auc наилучшей модели на валидационной выборке: 0.7955305073949143\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "roc_auc = 0\n",
    "best_depth = 0\n",
    "for est in range(1, 20):\n",
    "    for depth in range(1, 20):\n",
    "        model_forest = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        # обучите модель с заданным количеством деревьев И ГЛУБИНЫ ДЕРЕВЬЕВ\n",
    "        model_forest.fit(features_train, target_train) # обучите модель на тренировочной выборке\n",
    "        predictions = model_forest.predict(features_valid)\n",
    "        result = f1_score(target_valid, predictions) # посчитайте качество модели на валидационной выборке\n",
    "        probabilities_valid = model_forest.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "        auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "        if result > best_result:\n",
    "            best_model = model_forest# сохраните наилучшую модель\n",
    "            best_result = result#  сохраните наилучшее значение метрики F1 на валидационных данных\n",
    "            best_est = est\n",
    "            roc_auc = auc_roc\n",
    "            best_depth = depth\n",
    "        \n",
    "print(\"Наилучшая n_estimators:\", best_est)\n",
    "print(\"Наилучшая depth:\", best_depth)\n",
    "print(\"F1-мера наилучшей модели на валидационной выборке:\", best_result)\n",
    "print(\"roc_auc наилучшей модели на валидационной выборке:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера модели логистической регрессии на валидационной выборке: 0.3054003724394786\n",
      "roc_auc модели логистической регрессии на валидационной выборке: 0.7657919861309692\n"
     ]
    }
   ],
   "source": [
    "model_log = LogisticRegression(random_state=12345)\n",
    "# инициализируйте модель логистической регрессии с параметром random_state=12345\n",
    "model_log.fit(features_train, target_train) # обучите модель на тренировочной выборке\n",
    "predictions = model_log.predict(features_valid)\n",
    "result = f1_score(target_valid, predictions) # получите метрику качества модели на валидационной выборке\n",
    "probabilities_valid = model_log.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print(\"F1-мера модели логистической регрессии на валидационной выборке:\", result)\n",
    "print(\"roc_auc модели логистической регрессии на валидационной выборке:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да на логистической регрессии вообще все очень плохо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделим исходные данные на обучающую, валидационную и тестовую выборки учитывая стратификацию классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение талицы с учетом баланса классов\n",
    "\n",
    "Разделим таблицу сначала на 60 и 40 процентов и далее вторую выборку 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_ohe_drop.drop(['exited'], axis=1)\n",
    "target = df_ohe_drop['exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_40, target_train, target_40 = train_test_split(features, target, stratify=target,\n",
    "                                                              test_size=0.4, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_valid, features_test, target_valid, target_test = train_test_split(features_40, target_40, stratify=target_40,\n",
    "                                                              test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 11)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 11)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 11)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_products</th>\n",
       "      <th>has_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6612</th>\n",
       "      <td>-1.536794</td>\n",
       "      <td>2.391296</td>\n",
       "      <td>-0.496044</td>\n",
       "      <td>1.012552</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.015735</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>0.584295</td>\n",
       "      <td>1.819175</td>\n",
       "      <td>0.468147</td>\n",
       "      <td>0.211558</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.458737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>-0.326221</td>\n",
       "      <td>-0.373958</td>\n",
       "      <td>1.110941</td>\n",
       "      <td>0.894421</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.598309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3475</th>\n",
       "      <td>1.225795</td>\n",
       "      <td>-0.755372</td>\n",
       "      <td>-0.174647</td>\n",
       "      <td>-0.243433</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-1.616694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>-0.139979</td>\n",
       "      <td>-0.087897</td>\n",
       "      <td>-0.496044</td>\n",
       "      <td>0.446414</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>0.344174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063</th>\n",
       "      <td>-0.429689</td>\n",
       "      <td>-0.660018</td>\n",
       "      <td>0.789544</td>\n",
       "      <td>-0.073944</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.901353</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5951</th>\n",
       "      <td>0.729150</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>0.789544</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-0.679412</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9702</th>\n",
       "      <td>-0.067552</td>\n",
       "      <td>-0.755372</td>\n",
       "      <td>0.146750</td>\n",
       "      <td>0.152585</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-0.455023</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7518</th>\n",
       "      <td>-1.557488</td>\n",
       "      <td>-0.850726</td>\n",
       "      <td>-0.817441</td>\n",
       "      <td>0.785485</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-0.543976</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>-0.212407</td>\n",
       "      <td>-0.755372</td>\n",
       "      <td>-1.460235</td>\n",
       "      <td>0.575174</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.540411</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      credit_score       age    tenure   balance  num_products  has_card  \\\n",
       "6612     -1.536794  2.391296 -0.496044  1.012552     -0.911583 -1.547768   \n",
       "519       0.584295  1.819175  0.468147  0.211558     -0.911583 -1.547768   \n",
       "1609     -0.326221 -0.373958  1.110941  0.894421     -0.911583  0.646092   \n",
       "3475      1.225795 -0.755372 -0.174647 -0.243433      0.807737  0.646092   \n",
       "2707     -0.139979 -0.087897 -0.496044  0.446414     -0.911583 -1.547768   \n",
       "...            ...       ...       ...       ...           ...       ...   \n",
       "3063     -0.429689 -0.660018  0.789544 -0.073944     -0.911583  0.646092   \n",
       "5951      0.729150  0.198164  0.789544 -1.225848      0.807737 -1.547768   \n",
       "9702     -0.067552 -0.755372  0.146750  0.152585     -0.911583  0.646092   \n",
       "7518     -1.557488 -0.850726 -0.817441  0.785485      0.807737  0.646092   \n",
       "828      -0.212407 -0.755372 -1.460235  0.575174      0.807737  0.646092   \n",
       "\n",
       "      active_member  estimated_salary  geography_Germany  geography_Spain  \\\n",
       "6612       0.970243          0.015735                  0                0   \n",
       "519        0.970243          0.458737                  0                0   \n",
       "1609      -1.030670         -0.598309                  0                0   \n",
       "3475       0.970243         -1.616694                  0                0   \n",
       "2707      -1.030670          0.344174                  0                0   \n",
       "...             ...               ...                ...              ...   \n",
       "3063       0.970243          0.901353                  0                0   \n",
       "5951       0.970243         -0.679412                  0                0   \n",
       "9702       0.970243         -0.455023                  0                1   \n",
       "7518       0.970243         -0.543976                  1                0   \n",
       "828        0.970243          0.540411                  1                0   \n",
       "\n",
       "      gender_Male  \n",
       "6612            0  \n",
       "519             1  \n",
       "1609            0  \n",
       "3475            1  \n",
       "2707            0  \n",
       "...           ...  \n",
       "3063            1  \n",
       "5951            1  \n",
       "9702            0  \n",
       "7518            1  \n",
       "828             0  \n",
       "\n",
       "[2000 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6612    0\n",
       "519     0\n",
       "1609    0\n",
       "3475    0\n",
       "2707    0\n",
       "       ..\n",
       "3063    0\n",
       "5951    0\n",
       "9702    0\n",
       "7518    0\n",
       "828     0\n",
       "Name: exited, Length: 2000, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследуем качество F1-меры разных моделей на данных c учетом баланса классов, меняя гиперпараметры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель решающего дерева:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая depth: 7\n",
      "F1-мера наилучшей модели на валидационной выборке с балансом классов: 0.5924855491329479\n",
      "roc_auc наилучшей модели на валидационной выборке с балансом классов: 0.8247056360232534\n",
      "Wall time: 926 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model = None\n",
    "best_result = 0\n",
    "roc_auc = 0\n",
    "best_depth = 0\n",
    "for depth in range(1, 20):\n",
    "    model_tree_bal = DecisionTreeClassifier(random_state=12345, max_depth=depth) # обучите модель с заданной глубиной дерева\n",
    "    model_tree_bal.fit(features_train, target_train) # обучите модель\n",
    "    predictions = model_tree_bal.predict(features_valid) # получите предсказания модели\n",
    "    result = f1_score(target_valid, predictions) # посчитайте качество модели\n",
    "    probabilities_valid = model_tree_bal.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    if result > best_result:\n",
    "        best_model = model_tree_bal# сохраните наилучшую модель\n",
    "        best_result = result\n",
    "        roc_auc = auc_roc\n",
    "        best_depth = depth\n",
    "print(\"Наилучшая depth:\", best_depth)\n",
    "print(\"F1-мера наилучшей модели на валидационной выборке с балансом классов:\", best_result)\n",
    "print(\"roc_auc наилучшей модели на валидационной выборке с балансом классов:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Баланс классов улучшил модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая n_estimators: 15\n",
      "Наилучшая depth: 18\n",
      "F1-мера наилучшей модели на валидационной выборке с балансом классов: 0.6246418338108882\n",
      "roc_auc наилучшей модели на валидационной выборке с балансом классов: 0.8436098999901468\n",
      "Wall time: 29.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "roc_auc = 0\n",
    "best_depth = 0\n",
    "for est in range(1, 20):\n",
    "    for depth in range(1, 20):\n",
    "        model_forest_bal = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        # обучите модель с заданным количеством деревьев И ГЛУБИНЫ ДЕРЕВЬЕВ\n",
    "        model_forest_bal.fit(features_train, target_train) # обучите модель на тренировочной выборке\n",
    "        predictions = model_forest_bal.predict(features_valid)\n",
    "        result = f1_score(target_valid, predictions) # посчитайте качество модели на валидационной выборке\n",
    "        probabilities_valid = model_forest_bal.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "        auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "        if result > best_result:\n",
    "            best_model = model_forest_bal# сохраните наилучшую модель\n",
    "            best_result = result#  сохраните наилучшее значение метрики F1 на валидационных данных\n",
    "            best_est = est\n",
    "            roc_auc = auc_roc\n",
    "            best_depth = depth\n",
    "        \n",
    "print(\"Наилучшая n_estimators:\", best_est)\n",
    "print(\"Наилучшая depth:\", best_depth)\n",
    "print(\"F1-мера наилучшей модели на валидационной выборке с балансом классов:\", best_result)\n",
    "print(\"roc_auc наилучшей модели на валидационной выборке с балансом классов:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Баланс классов улучшил модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера модели логистической регрессии на валидационной выборке с балансом классов: 0.30458715596330277\n",
      "roc_auc модели логистической регрессии на валидационной выборке с балансом классов: 0.7875144718691497\n",
      "Wall time: 40.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_log = LogisticRegression(random_state=12345)\n",
    "# инициализируйте модель логистической регрессии с параметром random_state=12345\n",
    "model_log.fit(features_train, target_train) # обучите модель на тренировочной выборке\n",
    "predictions = model_log.predict(features_valid)\n",
    "result = f1_score(target_valid, predictions) # получите метрику качества модели на валидационной выборке\n",
    "probabilities_valid = model_log.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print(\"F1-мера модели логистической регрессии на валидационной выборке с балансом классов:\", result)\n",
    "print(\"roc_auc модели логистической регрессии на валидационной выборке с балансом классов:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решающего дерева и случайного леса баланс классов дал существенное улучшение F1-меры, для логистической регрессии стало даже немного хуже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверим качество модели на тестовой выборке с учетом баланса классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель решающего дерева - обучение на 60% данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера наилучшей модели на тестовой выборке с балансом классов: 0.4724602203182375\n",
      "auc_roc наилучшей модели на тестовой выборке с балансом классов: 0.6666543276712767\n",
      "Wall time: 30.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = model_tree_bal.predict(features_test) # получите предсказания модели\n",
    "result = f1_score(target_test, predictions) # посчитайте качество модели на тестовой выборке\n",
    "probabilities_test = model_tree_bal.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "print(\"F1-мера наилучшей модели на тестовой выборке с балансом классов:\", result)\n",
    "print(\"auc_roc наилучшей модели на тестовой выборке с балансом классов:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель случайного леса - обучение на 60% данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера наилучшей модели на тестовой выборке с балансом классов: 0.5327380952380952\n",
      "roc_auc наилучшей модели на тестовой выборке с балансом классов: 0.8436098999901468\n",
      "Wall time: 74.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = model_forest_bal.predict(features_test)\n",
    "result = f1_score(target_test, predictions) # посчитайте качество модели на валидационной выборке\n",
    "probabilities_test = model_forest_bal.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "        \n",
    "print(\"F1-мера наилучшей модели на тестовой выборке с балансом классов:\", result)\n",
    "print(\"roc_auc наилучшей модели на тестовой выборке с балансом классов:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовой выборке видим падение показателей качества модели, но мы использовали для обучения только 60% данных, далее попробуем разделить данные так, что бы использовать для обучения 80% данных\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделим данные на тренировочные и тестовые 80\\20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, stratify=target,\n",
    "                                                              test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель решающего дерева - обучение на 80% данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая depth: 7\n",
      "F1-мера наилучшей модели на тестовой выборке с балансом классов: 0.574404761904762\n",
      "roc_auc наилучшей модели на тестовой выборке с балансом классов: 0.8371730744612101\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model = None\n",
    "best_result = 0\n",
    "roc_auc = 0\n",
    "best_depth = 0\n",
    "for depth in range(1, 20):\n",
    "    model_tree = DecisionTreeClassifier(random_state=12345, max_depth=depth) # обучите модель с заданной глубиной дерева\n",
    "    model_tree.fit(features_train, target_train) # обучите модель\n",
    "    predictions = model_tree.predict(features_test) # получите предсказания модели\n",
    "    result = f1_score(target_test, predictions) # посчитайте качество модели\n",
    "    probabilities_test = model_tree.predict_proba(features_test)\n",
    "    probabilities_one_test = probabilities_test[:, 1]\n",
    "    auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "    if result > best_result:\n",
    "        best_model = model_tree# сохраните наилучшую модель\n",
    "        best_result = result\n",
    "        roc_auc = auc_roc\n",
    "        best_depth = depth\n",
    "print(\"Наилучшая depth:\", best_depth)\n",
    "print(\"F1-мера наилучшей модели на тестовой выборке с балансом классов:\", best_result)\n",
    "print(\"roc_auc наилучшей модели на тестовой выборке с балансом классов:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Модель случайного леса - обучение на 80% данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая n_estimators: 19\n",
      "Наилучшая depth: 14\n",
      "F1-мера наилучшей модели на тестовой выборке с балансом классов: 0.6000000000000001\n",
      "roc_auc наилучшей модели на тестовой выборке с балансом классов: 0.8608415811805642\n",
      "Accuracy модели: 0.8575\n",
      "Wall time: 37.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "roc_auc = 0\n",
    "best_depth = 0\n",
    "for est in range(1, 20):\n",
    "    for depth in range(1, 20):\n",
    "        model_forest = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        # обучите модель с заданным количеством деревьев И ГЛУБИНЫ ДЕРЕВЬЕВ\n",
    "        model_forest.fit(features_train, target_train) # обучите модель на тренировочной выборке\n",
    "        predictions = model_forest.predict(features_test)\n",
    "        result = f1_score(target_test, predictions) # посчитайте качество модели на валидационной выборке\n",
    "        probabilities_test = model_forest.predict_proba(features_test)\n",
    "        probabilities_one_test = probabilities_test[:, 1]\n",
    "        auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "        if result > best_result:\n",
    "            best_model = model_forest# сохраните наилучшую модель\n",
    "            best_result = result#  сохраните наилучшее значение метрики F1 на валидационных данных\n",
    "            best_est = est\n",
    "            roc_auc = auc_roc\n",
    "            best_depth = depth\n",
    "        \n",
    "print(\"Наилучшая n_estimators:\", best_est)\n",
    "print(\"Наилучшая depth:\", best_depth)\n",
    "print(\"F1-мера наилучшей модели на тестовой выборке с балансом классов:\", best_result)\n",
    "print(\"roc_auc наилучшей модели на тестовой выборке с балансом классов:\", roc_auc)\n",
    "print(\"Accuracy модели:\",model_forest.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель случайного леса на данных без массштабирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_ohe.drop(['exited'], axis=1)\n",
    "target = df_ohe['exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, stratify=target,\n",
    "                                                              test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая n_estimators: 19\n",
      "Наилучшая depth: 14\n",
      "F1-мера наилучшей модели на тестовой выборке с балансом классов: 0.6000000000000001\n",
      "roc_auc наилучшей модели на тестовой выборке с балансом классов: 0.861261107023819\n",
      "Accuracy модели: 0.859\n",
      "Wall time: 42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "roc_auc = 0\n",
    "best_depth = 0\n",
    "for est in range(1, 20):\n",
    "    for depth in range(1, 20):\n",
    "        model_forest = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        # обучите модель с заданным количеством деревьев И ГЛУБИНЫ ДЕРЕВЬЕВ\n",
    "        model_forest.fit(features_train, target_train) # обучите модель на тренировочной выборке\n",
    "        predictions = model_forest.predict(features_test)\n",
    "        result = f1_score(target_test, predictions) # посчитайте качество модели на валидационной выборке\n",
    "        probabilities_test = model_forest.predict_proba(features_test)\n",
    "        probabilities_one_test = probabilities_test[:, 1]\n",
    "        auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "        if result > best_result:\n",
    "            best_model = model_forest# сохраните наилучшую модель\n",
    "            best_result = result#  сохраните наилучшее значение метрики F1 на валидационных данных\n",
    "            best_est = est\n",
    "            roc_auc = auc_roc\n",
    "            best_depth = depth\n",
    "        \n",
    "print(\"Наилучшая n_estimators:\", best_est)\n",
    "print(\"Наилучшая depth:\", best_depth)\n",
    "print(\"F1-мера наилучшей модели на тестовой выборке с балансом классов:\", best_result)\n",
    "print(\"roc_auc наилучшей модели на тестовой выборке с балансом классов:\", roc_auc)\n",
    "print(\"Accuracy модели:\",model_forest.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Массштабирование данных не повлияло на результат F1 и незначительно увеличило roc_auc и Accuracy\n",
    "    \n",
    "    В данном случае это лучшая модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC кривая лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(target_test, probabilities_one_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривая')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель случайного леса на данных без массштабирования с Дамми-ловушкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe_dummy = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_products</th>\n",
       "      <th>has_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_France</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_score  age  tenure    balance  num_products  has_card  \\\n",
       "0           619   42       2       0.00             1         1   \n",
       "1           608   41       1   83807.86             1         0   \n",
       "2           502   42       8  159660.80             3         1   \n",
       "3           699   39       1       0.00             2         0   \n",
       "4           850   43       2  125510.82             1         1   \n",
       "\n",
       "   active_member  estimated_salary  exited  geography_France  \\\n",
       "0              1         101348.88       1                 1   \n",
       "1              1         112542.58       0                 0   \n",
       "2              0         113931.57       1                 1   \n",
       "3              0          93826.63       0                 1   \n",
       "4              1          79084.10       0                 0   \n",
       "\n",
       "   geography_Germany  geography_Spain  gender_Female  gender_Male  \n",
       "0                  0                0              1            0  \n",
       "1                  0                1              1            0  \n",
       "2                  0                0              1            0  \n",
       "3                  0                0              1            0  \n",
       "4                  0                1              1            0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ohe_dummy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_ohe_dummy.drop(['exited'], axis=1)\n",
    "target = df_ohe_dummy['exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, stratify=target,\n",
    "                                                              test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая n_estimators: 13\n",
      "Наилучшая depth: 18\n",
      "F1-мера наилучшей модели на тестовой выборке с Дамми-ловушкой: 0.5853658536585367\n",
      "roc_auc наилучшей модели на тестовой выборке с Дамми-ловушкой: 0.8353823777552591\n",
      "Accuracy модели с Дамми-ловушкой: 0.852\n",
      "Wall time: 30.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "roc_auc = 0\n",
    "best_depth = 0\n",
    "for est in range(1, 20):\n",
    "    for depth in range(1, 20):\n",
    "        model_forest = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        # обучите модель с заданным количеством деревьев И ГЛУБИНЫ ДЕРЕВЬЕВ\n",
    "        model_forest.fit(features_train, target_train) # обучите модель на тренировочной выборке\n",
    "        predictions = model_forest.predict(features_test)\n",
    "        result = f1_score(target_test, predictions) # посчитайте качество модели на валидационной выборке\n",
    "        probabilities_test = model_forest.predict_proba(features_test)\n",
    "        probabilities_one_test = probabilities_test[:, 1]\n",
    "        auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "        if result > best_result:\n",
    "            best_model = model_forest# сохраните наилучшую модель\n",
    "            best_result = result#  сохраните наилучшее значение метрики F1 на валидационных данных\n",
    "            best_est = est\n",
    "            roc_auc = auc_roc\n",
    "            best_depth = depth\n",
    "        \n",
    "print(\"Наилучшая n_estimators:\", best_est)\n",
    "print(\"Наилучшая depth:\", best_depth)\n",
    "print(\"F1-мера наилучшей модели на тестовой выборке с Дамми-ловушкой:\", best_result)\n",
    "print(\"roc_auc наилучшей модели на тестовой выборке с Дамми-ловушкой:\", roc_auc)\n",
    "print(\"Accuracy модели с Дамми-ловушкой:\",model_forest.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка на адекватность моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того что бы модели были адекватные Accuracy должно быть больше процентного отношения наибольшего класса в целевом признаке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.7963\n",
       "1    0.2037\n",
       "Name: exited, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['exited'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy наилучшей модели: 0.859, что больше процентного содержания нулей в целевых данных.\n",
    "\n",
    "Баланс классов сохраняет это отношение для всех выборок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### А что если мы уменьшим количество данных с нулями?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция уменьшения данных с классом целевого признака - ноль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.661475\n",
       "1    0.338525\n",
       "Name: exited, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_downsampled.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4815,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_downsampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменили соотношение на тренировочных выборках, оставив в тестовой прежнее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая n_estimators: 12\n",
      "Наилучшая depth: 9\n",
      "F1-мера наилучшей модели на тестовой выборке с Дамми-ловушкой: 0.6294416243654822\n",
      "roc_auc наилучшей модели на тестовой выборке с Дамми-ловушкой: 0.8552219399677027\n",
      "Accuracy модели с Дамми-ловушкой: 0.838\n",
      "Wall time: 25.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "roc_auc = 0\n",
    "best_depth = 0\n",
    "for est in range(1, 20):\n",
    "    for depth in range(1, 20):\n",
    "        model_forest = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        # обучите модель с заданным количеством деревьев И ГЛУБИНЫ ДЕРЕВЬЕВ\n",
    "        model_forest.fit(features_downsampled, target_downsampled) # обучите модель на тренировочной выборке\n",
    "        predictions = model_forest.predict(features_test)\n",
    "        result = f1_score(target_test, predictions) # посчитайте качество модели на валидационной выборке\n",
    "        probabilities_test = model_forest.predict_proba(features_test)\n",
    "        probabilities_one_test = probabilities_test[:, 1]\n",
    "        auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "        if result > best_result:\n",
    "            best_model = model_forest# сохраните наилучшую модель\n",
    "            best_result = result#  сохраните наилучшее значение метрики F1 на валидационных данных\n",
    "            best_est = est\n",
    "            roc_auc = auc_roc\n",
    "            best_depth = depth\n",
    "        \n",
    "print(\"Наилучшая n_estimators:\", best_est)\n",
    "print(\"Наилучшая depth:\", best_depth)\n",
    "print(\"F1-мера наилучшей модели на тестовой выборке с Дамми-ловушкой:\", best_result)\n",
    "print(\"roc_auc наилучшей модели на тестовой выборке с Дамми-ловушкой:\", roc_auc)\n",
    "print(\"Accuracy модели с Дамми-ловушкой:\",model_forest.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ХМ, в модели с дамми-ловушкой наблюдаетя увеличение показателей качества модели (то есть на лучшей модели предположительно эти показатели будут еще больше на 0,02-0,03), правда немного снижается Accuracy и хорошо так снижается время обучения модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Посчитаем метрики без дамми ловушки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_ohe.drop(['exited'], axis=1)\n",
    "target = df_ohe['exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, stratify=target,\n",
    "                                                              test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая n_estimators: 16\n",
      "Наилучшая depth: 10\n",
      "F1-мера наилучшей модели на тестовой выборке: 0.6507537688442212\n",
      "roc_auc наилучшей модели на тестовой выборке: 0.8644869831310509\n",
      "Accuracy модели: 0.841\n",
      "Wall time: 23.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "roc_auc = 0\n",
    "best_depth = 0\n",
    "for est in range(1, 20):\n",
    "    for depth in range(1, 20):\n",
    "        model_forest = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        # обучите модель с заданным количеством деревьев И ГЛУБИНЫ ДЕРЕВЬЕВ\n",
    "        model_forest.fit(features_downsampled, target_downsampled) # обучите модель на тренировочной выборке\n",
    "        predictions = model_forest.predict(features_test)\n",
    "        result = f1_score(target_test, predictions) # посчитайте качество модели на валидационной выборке\n",
    "        probabilities_test = model_forest.predict_proba(features_test)\n",
    "        probabilities_one_test = probabilities_test[:, 1]\n",
    "        auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "        if result > best_result:\n",
    "            best_model = model_forest# сохраните наилучшую модель\n",
    "            best_result = result#  сохраните наилучшее значение метрики F1 на валидационных данных\n",
    "            best_est = est\n",
    "            roc_auc = auc_roc\n",
    "            best_depth = depth\n",
    "        \n",
    "print(\"Наилучшая n_estimators:\", best_est)\n",
    "print(\"Наилучшая depth:\", best_depth)\n",
    "print(\"F1-мера наилучшей модели на тестовой выборке:\", best_result)\n",
    "print(\"roc_auc наилучшей модели на тестовой выборке:\", roc_auc)\n",
    "print(\"Accuracy модели:\",model_forest.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересно, а что будет если еще сильнее сбалансируем классы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.539678\n",
       "1    0.460322\n",
       "Name: exited, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_downsampled.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая n_estimators: 18\n",
      "Наилучшая depth: 5\n",
      "F1-мера наилучшей модели на тестовой выборке: 0.6235662148070906\n",
      "roc_auc наилучшей модели на тестовой выборке: 0.8506942998468422\n",
      "Accuracy модели: 0.789\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "roc_auc = 0\n",
    "best_depth = 0\n",
    "for est in range(1, 20):\n",
    "    for depth in range(1, 20):\n",
    "        model_forest = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        # обучите модель с заданным количеством деревьев И ГЛУБИНЫ ДЕРЕВЬЕВ\n",
    "        model_forest.fit(features_downsampled, target_downsampled) # обучите модель на тренировочной выборке\n",
    "        predictions = model_forest.predict(features_test)\n",
    "        result = f1_score(target_test, predictions) # посчитайте качество модели на валидационной выборке\n",
    "        probabilities_test = model_forest.predict_proba(features_test)\n",
    "        probabilities_one_test = probabilities_test[:, 1]\n",
    "        auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "        if result > best_result:\n",
    "            best_model = model_forest# сохраните наилучшую модель\n",
    "            best_result = result#  сохраните наилучшее значение метрики F1 на валидационных данных\n",
    "            best_est = est\n",
    "            roc_auc = auc_roc\n",
    "            best_depth = depth\n",
    "        \n",
    "print(\"Наилучшая n_estimators:\", best_est)\n",
    "print(\"Наилучшая depth:\", best_depth)\n",
    "print(\"F1-мера наилучшей модели на тестовой выборке:\", best_result)\n",
    "print(\"roc_auc наилучшей модели на тестовой выборке:\", roc_auc)\n",
    "print(\"Accuracy модели:\",model_forest.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдаем уменьшение качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть по идее можно найти такой баланс классов на обучающей выборке, что можно максимизировать метрики качества модели, при этом уменьшая время обучения модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Увеличим максимальные значения в циклах для n_estimators и depth. Посмотрим найдется ли модель с еще лучшими показателям параметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая n_estimators: 27\n",
      "Наилучшая depth: 12\n",
      "F1-мера наилучшей модели на тестовой выборке: 0.6307385229540918\n",
      "roc_auc наилучшей модели на тестовой выборке: 0.8619621161994043\n",
      "Accuracy модели: 0.7925\n",
      "Wall time: 5min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "roc_auc = 0\n",
    "best_depth = 0\n",
    "for est in range(1, 30):\n",
    "    for depth in range(1, 100):\n",
    "        model_forest = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        # обучите модель с заданным количеством деревьев И ГЛУБИНЫ ДЕРЕВЬЕВ\n",
    "        model_forest.fit(features_downsampled, target_downsampled) # обучите модель на тренировочной выборке\n",
    "        predictions = model_forest.predict(features_test)\n",
    "        result = f1_score(target_test, predictions) # посчитайте качество модели на валидационной выборке\n",
    "        probabilities_test = model_forest.predict_proba(features_test)\n",
    "        probabilities_one_test = probabilities_test[:, 1]\n",
    "        auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "        if result > best_result:\n",
    "            best_model = model_forest# сохраните наилучшую модель\n",
    "            best_result = result#  сохраните наилучшее значение метрики F1 на валидационных данных\n",
    "            best_est = est\n",
    "            roc_auc = auc_roc\n",
    "            best_depth = depth\n",
    "        \n",
    "print(\"Наилучшая n_estimators:\", best_est)\n",
    "print(\"Наилучшая depth:\", best_depth)\n",
    "print(\"F1-мера наилучшей модели на тестовой выборке:\", best_result)\n",
    "print(\"roc_auc наилучшей модели на тестовой выборке:\", roc_auc)\n",
    "print(\"Accuracy модели:\",model_forest.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдаем улучшение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обобщим исследования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Без стратификации по классам целевого признака имеем наилучшие показатели следующие:\n",
    "\n",
    "F1 случайного леса: 0.55\n",
    "\n",
    "AUC-ROC случайного леса: 0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* С учетом баланса классов целевого признака:\n",
    "\n",
    "F1 случайного леса: 0.60\n",
    "\n",
    "AUC-ROC случайного леса: 0.86\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Введение в выборки баланса классов повышает качество модели по F1 и AUC-ROC на 0.05 - 0.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Увеличение тренировочной выборки на 20% не гарантирует повышение показателя F1, а показывает даже снижение этого показателя на 0.02 (видимо влияние - какие именно данные мы взяли для обучения), тогда как показатель AUC-ROC растет на  0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Модели с масштабированием и без масштабирования данных показали практически одинаковое качество"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ловушка фиктивных признаков уменьшила качество модели, хотя и уменьшила время обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Увеличение тренировочных данных с 60 до 80% (от 10000) увеличило время обучения на 3-5 секунды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Улучшение баланса классов в тренировочных выборках положительно сказывается на качестве модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Можно найти такой баланс классов на обучающей выборке, что можно максимизировать метрики качества модели, при этом уменьшая время обучения модели.\n",
    "\n",
    "в нашем случае при балансе классов 1/0  - 66/34 %, получаем наилучшие показатели качества:\n",
    "\n",
    "F1: 0.65\n",
    "\n",
    "AUC-ROC: 0.85\n",
    "\n",
    "Accuracy: 0.841"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Вывод: \n",
    "    \n",
    "Наилучшая модель хорошо описывает данные, предоставленные банком, предсказывая возможность ухода клента. Значит имея подобные данные по клиенту, можно предсказать его возможный уход из банка и предложить ему лучшие условия или продукты банка, для сохранения лояльности клента банку."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 909,
    "start_time": "2021-10-24T06:15:41.156Z"
   },
   {
    "duration": 16,
    "start_time": "2021-10-24T06:15:42.067Z"
   },
   {
    "duration": 248,
    "start_time": "2021-10-24T06:15:42.086Z"
   },
   {
    "duration": 23,
    "start_time": "2021-10-24T06:15:42.337Z"
   },
   {
    "duration": 12,
    "start_time": "2021-10-24T06:15:42.362Z"
   },
   {
    "duration": 49,
    "start_time": "2021-10-24T06:15:42.376Z"
   },
   {
    "duration": 6,
    "start_time": "2021-10-24T06:15:42.427Z"
   },
   {
    "duration": 5,
    "start_time": "2021-10-24T06:15:42.436Z"
   },
   {
    "duration": 6,
    "start_time": "2021-10-24T06:15:42.443Z"
   },
   {
    "duration": 17,
    "start_time": "2021-10-24T06:15:42.482Z"
   },
   {
    "duration": 8,
    "start_time": "2021-10-24T06:15:42.501Z"
   },
   {
    "duration": 7,
    "start_time": "2021-10-24T06:15:42.511Z"
   },
   {
    "duration": 71,
    "start_time": "2021-10-24T06:15:42.520Z"
   },
   {
    "duration": 917,
    "start_time": "2021-10-24T06:15:42.593Z"
   },
   {
    "duration": 969,
    "start_time": "2021-10-24T06:15:43.513Z"
   },
   {
    "duration": 5,
    "start_time": "2021-10-24T06:15:44.484Z"
   },
   {
    "duration": 22,
    "start_time": "2021-10-24T06:15:44.491Z"
   },
   {
    "duration": 8,
    "start_time": "2021-10-24T06:15:44.515Z"
   },
   {
    "duration": 6,
    "start_time": "2021-10-24T06:15:44.525Z"
   },
   {
    "duration": 12,
    "start_time": "2021-10-24T06:15:44.534Z"
   },
   {
    "duration": 48,
    "start_time": "2021-10-24T06:15:44.548Z"
   },
   {
    "duration": 18,
    "start_time": "2021-10-24T06:15:44.598Z"
   },
   {
    "duration": 489,
    "start_time": "2021-10-24T06:15:44.623Z"
   },
   {
    "duration": 5,
    "start_time": "2021-10-24T06:15:45.116Z"
   },
   {
    "duration": 34,
    "start_time": "2021-10-24T06:15:45.123Z"
   },
   {
    "duration": 35,
    "start_time": "2021-10-24T06:15:45.159Z"
   },
   {
    "duration": 9,
    "start_time": "2021-10-24T06:15:45.197Z"
   },
   {
    "duration": 5,
    "start_time": "2021-10-24T06:15:45.209Z"
   },
   {
    "duration": 7,
    "start_time": "2021-10-24T06:15:45.216Z"
   },
   {
    "duration": 6,
    "start_time": "2021-10-24T06:15:45.225Z"
   },
   {
    "duration": 50,
    "start_time": "2021-10-24T06:15:45.233Z"
   },
   {
    "duration": 5,
    "start_time": "2021-10-24T06:15:45.285Z"
   },
   {
    "duration": 8,
    "start_time": "2021-10-24T06:15:45.292Z"
   },
   {
    "duration": 138,
    "start_time": "2021-10-24T06:15:45.302Z"
   },
   {
    "duration": 619,
    "start_time": "2021-10-24T06:15:45.442Z"
   },
   {
    "duration": 30709,
    "start_time": "2021-10-24T06:15:46.063Z"
   },
   {
    "duration": 115,
    "start_time": "2021-10-24T06:16:16.774Z"
   },
   {
    "duration": 91,
    "start_time": "2021-10-24T06:16:16.892Z"
   },
   {
    "duration": 7,
    "start_time": "2021-10-24T06:16:16.986Z"
   },
   {
    "duration": 17,
    "start_time": "2021-10-24T06:16:16.995Z"
   },
   {
    "duration": 9,
    "start_time": "2021-10-24T06:16:17.015Z"
   },
   {
    "duration": 5,
    "start_time": "2021-10-24T06:16:17.027Z"
   },
   {
    "duration": 5,
    "start_time": "2021-10-24T06:16:17.034Z"
   },
   {
    "duration": 44,
    "start_time": "2021-10-24T06:16:17.041Z"
   },
   {
    "duration": 22,
    "start_time": "2021-10-24T06:16:17.087Z"
   },
   {
    "duration": 7,
    "start_time": "2021-10-24T06:16:17.112Z"
   },
   {
    "duration": 649,
    "start_time": "2021-10-24T06:16:17.121Z"
   },
   {
    "duration": 31165,
    "start_time": "2021-10-24T06:16:17.772Z"
   },
   {
    "duration": 143,
    "start_time": "2021-10-24T06:16:48.939Z"
   },
   {
    "duration": 102,
    "start_time": "2021-10-24T06:16:49.085Z"
   },
   {
    "duration": 38,
    "start_time": "2021-10-24T06:16:49.190Z"
   },
   {
    "duration": 15,
    "start_time": "2021-10-24T06:16:49.230Z"
   },
   {
    "duration": 36,
    "start_time": "2021-10-24T06:16:49.247Z"
   },
   {
    "duration": 863,
    "start_time": "2021-10-24T06:16:49.287Z"
   },
   {
    "duration": 39107,
    "start_time": "2021-10-24T06:16:50.153Z"
   },
   {
    "duration": 29,
    "start_time": "2021-10-24T06:17:29.262Z"
   },
   {
    "duration": 7,
    "start_time": "2021-10-24T06:17:29.293Z"
   },
   {
    "duration": 13,
    "start_time": "2021-10-24T06:17:29.302Z"
   },
   {
    "duration": 38613,
    "start_time": "2021-10-24T06:17:29.318Z"
   },
   {
    "duration": 3,
    "start_time": "2021-10-24T06:18:07.933Z"
   },
   {
    "duration": 8,
    "start_time": "2021-10-24T06:18:07.939Z"
   },
   {
    "duration": 284,
    "start_time": "2021-10-24T06:18:07.950Z"
   },
   {
    "duration": 22,
    "start_time": "2021-10-24T06:18:08.237Z"
   },
   {
    "duration": 34,
    "start_time": "2021-10-24T06:18:08.261Z"
   },
   {
    "duration": 7,
    "start_time": "2021-10-24T06:18:08.297Z"
   },
   {
    "duration": 13,
    "start_time": "2021-10-24T06:18:08.306Z"
   },
   {
    "duration": 36379,
    "start_time": "2021-10-24T06:18:08.321Z"
   },
   {
    "duration": 14,
    "start_time": "2021-10-24T06:18:44.707Z"
   },
   {
    "duration": 3,
    "start_time": "2021-10-24T06:18:44.724Z"
   },
   {
    "duration": 23,
    "start_time": "2021-10-24T06:18:44.729Z"
   },
   {
    "duration": 31,
    "start_time": "2021-10-24T06:18:44.754Z"
   },
   {
    "duration": 5,
    "start_time": "2021-10-24T06:18:44.787Z"
   },
   {
    "duration": 26328,
    "start_time": "2021-10-24T06:18:44.794Z"
   },
   {
    "duration": 18,
    "start_time": "2021-10-24T06:19:11.125Z"
   },
   {
    "duration": 7,
    "start_time": "2021-10-24T06:19:11.145Z"
   },
   {
    "duration": 35,
    "start_time": "2021-10-24T06:19:11.154Z"
   },
   {
    "duration": 18,
    "start_time": "2021-10-24T06:19:11.192Z"
   },
   {
    "duration": 27895,
    "start_time": "2021-10-24T06:19:11.212Z"
   },
   {
    "duration": 17,
    "start_time": "2021-10-24T06:19:39.109Z"
   },
   {
    "duration": 8,
    "start_time": "2021-10-24T06:19:39.128Z"
   },
   {
    "duration": 23828,
    "start_time": "2021-10-24T06:19:39.138Z"
   },
   {
    "duration": 5,
    "start_time": "2021-10-24T06:35:52.091Z"
   },
   {
    "duration": 6,
    "start_time": "2021-10-24T06:36:12.400Z"
   },
   {
    "duration": 6,
    "start_time": "2021-10-24T06:36:23.586Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "283px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
